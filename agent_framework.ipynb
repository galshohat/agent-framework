{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321ecba2",
   "metadata": {},
   "source": [
    "# Microsoft Agent Framework\n",
    "\n",
    "![Microsoft Agent Framework](images/maf.png)\n",
    "\n",
    "The **Microsoft Agent Framework** is a Python SDK for building AI agents and multi-agent workflows. It provides a unified interface for creating intelligent systems that can reason, take actions, and collaborate.\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Single and multi-agent orchestration\n",
    "- Tool integration and function calling\n",
    "- Memory and context management\n",
    "- Workflow patterns (sequential, parallel, branching)\n",
    "- Built-in observability and middleware\n",
    "\n",
    "---\n",
    "\n",
    "## What is an Agent?\n",
    "\n",
    "![What is an Agent](images/what-is-agent.png)\n",
    "\n",
    "Unlike traditional LLM deployments that simply respond to prompts, agents follow the **ReAct pattern** (Reasoning + Acting):\n",
    "\n",
    "| Traditional LLM | Agent (ReAct) |\n",
    "|-----------------|---------------|\n",
    "| Input â†’ Output | Input â†’ Reason â†’ Act â†’ Observe â†’ Repeat |\n",
    "| Single response | Multi-step execution |\n",
    "| No tool access | Tool integration |\n",
    "| Stateless | Memory & context |\n",
    "\n",
    "Agents autonomously decide *what* to do, *which* tools to use, and *when* to stop.\n",
    "\n",
    "---\n",
    "\n",
    "## Workflows & Multi-Agent Orchestration\n",
    "\n",
    "![Workflow Example](images/workflow-example.png)\n",
    "\n",
    "Complex tasks require coordination between multiple specialized agents. The Agent Framework provides workflow primitives:\n",
    "\n",
    "- **Sequential** â€” Agents execute in order (A â†’ B â†’ C)\n",
    "- **Parallel (Fan-out/Fan-in)** â€” Concurrent execution with result aggregation\n",
    "- **Branching** â€” Conditional routing based on outputs\n",
    "- **Group Chat** â€” Collaborative multi-agent discussions\n",
    "\n",
    "---\n",
    "\n",
    "## Demo Overview\n",
    "\n",
    "We'll build a **Support Email Copilot** that demonstrates core framework concepts:\n",
    "\n",
    "| Section | Concept |\n",
    "|---------|---------|\n",
    "| 1-2 | Agent basics & streaming |\n",
    "| 3-4 | Conversations & function tools |\n",
    "| 5-7 | Approvals, middleware, memory |\n",
    "| 8-10 | Workflows: sequential, branching, parallel |\n",
    "| 11-12 | Multi-agent collaboration & capstone |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure subscription with Azure OpenAI access\n",
    "- Azure OpenAI resource with deployed model (e.g., `gpt-4o-mini`)\n",
    "- Azure CLI installed and authenticated (`az login`)\n",
    "- Python 3.10+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d841bbb",
   "metadata": {},
   "source": [
    "# 0. Environment Setup\n",
    "\n",
    "## Create Virtual Environment\n",
    "\n",
    "Run the following in your terminal to set up the environment:\n",
    "\n",
    "```bash\n",
    "python3.10 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Or run the cell below to install dependencies directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0f53fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found Python 3.12: /Users/glswht/Desktop/magentic-workflow/SDK-Magentic-Workflow/.venv/bin/python3.12\n",
      "Requirement already satisfied: agent-framework in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: azure-identity>=1.15.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (1.26.0b1)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.12.5)\n",
      "Requirement already satisfied: agent-framework-core==1.0.0b260130 in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: pydantic-settings<3,>=2 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.39.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.39.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions-ai>=0.4.13 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.13)\n",
      "Requirement already satisfied: openai>=1.99.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.16.0)\n",
      "Requirement already satisfied: mcp<2,>=1.24.0 in ./.venv/lib/python3.12/site-packages (from mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.26.0)\n",
      "Requirement already satisfied: packaging>=24.1 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (26.0)\n",
      "Requirement already satisfied: agent-framework-a2a in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-ag-ui in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-azure-ai-search in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-anthropic in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-azure-ai in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-azurefunctions in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-chatkit in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-copilotstudio in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-declarative in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-devui in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-durabletask in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-github-copilot in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-lab in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b251024)\n",
      "Requirement already satisfied: agent-framework-mem0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-ollama in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-purview in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: agent-framework-redis in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.38.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (46.0.4)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.35.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: anyio>=4.5 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.12.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.26.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in ./.venv/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.22)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: starlette>=0.27 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.50.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.40.0)\n",
      "Requirement already satisfied: websockets>=15.0.1 in ./.venv/lib/python3.12/site-packages (from mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (16.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.32.5)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity>=1.15.0->-r requirements.txt (line 13)) (3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.30.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.6.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.67.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.60b1)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from uvicorn>=0.31.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (8.3.1)\n",
      "Requirement already satisfied: a2a-sdk>=0.3.5 in ./.venv/lib/python3.12/site-packages (from agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.3.22)\n",
      "Requirement already satisfied: google-api-core>=1.26.0 in ./.venv/lib/python3.12/site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.29.0)\n",
      "Requirement already satisfied: protobuf>=5.29.5 in ./.venv/lib/python3.12/site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.72.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.27.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.49.0.dev0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: ag-ui-protocol>=0.1.9 in ./.venv/lib/python3.12/site-packages (from agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.1.10)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.128.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from fastapi>=0.115.0->agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.4)\n",
      "Requirement already satisfied: anthropic<1,>=0.70.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-anthropic->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.77.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in ./.venv/lib/python3.12/site-packages (from anthropic<1,>=0.70.0->agent-framework-anthropic->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.17.0)\n",
      "Requirement already satisfied: azure-ai-projects>=2.0.0b3 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.0.0b3)\n",
      "Requirement already satisfied: azure-ai-agents==1.2.0b5 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.2.0b5)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.13.3)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.12/site-packages (from azure-ai-agents==1.2.0b5->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in ./.venv/lib/python3.12/site-packages (from azure-ai-projects>=2.0.0b3->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (12.29.0b1)\n",
      "Requirement already satisfied: azure-search-documents==11.7.0b2 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai-search->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (11.7.0b2)\n",
      "Requirement already satisfied: azure-common>=1.1 in ./.venv/lib/python3.12/site-packages (from azure-search-documents==11.7.0b2->agent-framework-azure-ai-search->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.1.28)\n",
      "Requirement already satisfied: azure-functions in ./.venv/lib/python3.12/site-packages (from agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.25.0b3.dev3)\n",
      "Requirement already satisfied: azure-functions-durable in ./.venv/lib/python3.12/site-packages (from agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: openai-chatkit<2.0.0,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: openai-agents>=0.3.2 in ./.venv/lib/python3.12/site-packages (from openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: jinja2<4,>=3.1 in ./.venv/lib/python3.12/site-packages (from openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2<4,>=3.1->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in ./.venv/lib/python3.12/site-packages (from openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in ./.venv/lib/python3.12/site-packages (from openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.32.4.20260107)\n",
      "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.12/site-packages (from griffe<2,>=1.5.6->openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: microsoft-agents-copilotstudio-client>=0.3.1 in ./.venv/lib/python3.12/site-packages (from agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: microsoft-agents-hosting-core==0.7.0 in ./.venv/lib/python3.12/site-packages (from microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: microsoft-agents-activity==0.7.0 in ./.venv/lib/python3.12/site-packages (from microsoft-agents-hosting-core==0.7.0->microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: powerfx>=0.0.31 in ./.venv/lib/python3.12/site-packages (from agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.34)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: pythonnet==3.0.5 in ./.venv/lib/python3.12/site-packages (from powerfx>=0.0.31->agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.0.5)\n",
      "Requirement already satisfied: clr_loader<0.3.0,>=0.2.7 in ./.venv/lib/python3.12/site-packages (from pythonnet==3.0.5->powerfx>=0.0.31->agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.2.10)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: durabletask>=1.3.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: durabletask-azuremanaged>=1.3.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: grpcio in ./.venv/lib/python3.12/site-packages (from durabletask>=1.3.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.78.0rc2)\n",
      "Requirement already satisfied: asyncio in ./.venv/lib/python3.12/site-packages (from durabletask>=1.3.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: github-copilot-sdk>=0.1.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-github-copilot->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.1.20)\n",
      "Requirement already satisfied: mem0ai>=1.0.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.3)\n",
      "Requirement already satisfied: posthog>=3.5.0 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (7.8.0)\n",
      "Requirement already satisfied: pytz>=2024.1 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: qdrant-client>=1.9.1 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.16.2)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.31 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.1.0b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog>=3.5.0->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.26 in ./.venv/lib/python3.12/site-packages (from qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.4.2)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in ./.venv/lib/python3.12/site-packages (from qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: h2<5,>=3 in ./.venv/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in ./.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in ./.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: ollama>=0.5.3 in ./.venv/lib/python3.12/site-packages (from agent-framework-ollama->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: redis>=6.4.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (7.1.0)\n",
      "Requirement already satisfied: redisvl>=0.8.2 in ./.venv/lib/python3.12/site-packages (from agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: jsonpath-ng>=1.5.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.5.4)\n",
      "Requirement already satisfied: python-ulid>=3.0.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: ply in ./.venv/lib/python3.12/site-packages (from jsonpath-ng>=1.5.0->redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: werkzeug~=3.1.3 in ./.venv/lib/python3.12/site-packages (from azure-functions->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.5)\n",
      "Requirement already satisfied: furl>=2.1.0 in ./.venv/lib/python3.12/site-packages (from azure-functions-durable->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.1.4)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in ./.venv/lib/python3.12/site-packages (from furl>=2.1.0->azure-functions-durable->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.2)\n",
      "\n",
      "âœ… Virtual environment created at .venv\n",
      "   Activate with: source .venv/bin/activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create and configure the virtual environment (run once)\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def find_python():\n",
    "    \"\"\"Find a Python 3.10+ interpreter on the system.\"\"\"\n",
    "    # Check common Python commands in order of preference\n",
    "    candidates = [\n",
    "        \"python3.13\", \"python3.12\", \"python3.11\", \"python3.10\",\n",
    "        \"python3\", \"python\"\n",
    "    ]\n",
    "    \n",
    "    for cmd in candidates:\n",
    "        path = shutil.which(cmd)\n",
    "        if path:\n",
    "            # Verify version is 3.10+\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [path, \"-c\", \"import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')\"],\n",
    "                    capture_output=True, text=True\n",
    "                )\n",
    "                version = result.stdout.strip()\n",
    "                major, minor = map(int, version.split('.'))\n",
    "                if major >= 3 and minor >= 10:\n",
    "                    return path, version\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    raise RuntimeError(\"No Python 3.10+ found. Please install Python 3.10 or higher.\")\n",
    "\n",
    "# Find suitable Python\n",
    "python_path, python_version = find_python()\n",
    "print(f\"âœ… Found Python {python_version}: {python_path}\")\n",
    "\n",
    "# Create .venv\n",
    "subprocess.run([python_path, \"-m\", \"venv\", \".venv\"])\n",
    "\n",
    "# Install requirements with pre-release flag\n",
    "subprocess.run([\".venv/bin/pip\", \"install\", \"-r\", \"requirements.txt\", \"--pre\"])\n",
    "\n",
    "print(\"\\nâœ… Virtual environment created at .venv\")\n",
    "print(\"   Activate with: source .venv/bin/activate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e423b",
   "metadata": {},
   "source": [
    "## Initialize Chat Client\n",
    "\n",
    "Load environment variables and create the Azure OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d946629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment loaded and chat_client created\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import AzureCliCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create ONE chat client - reused throughout the notebook\n",
    "chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "print(\"âœ… Environment loaded and chat_client created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10492593",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "Pydantic models for structured input/output throughout the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e398ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shared models defined: EmailInput, ClassificationResult, DraftResponse, FinalResponse\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# === Input Model ===\n",
    "class EmailInput(BaseModel):\n",
    "    \"\"\"Incoming support email.\"\"\"\n",
    "    sender: str = Field(description=\"Email sender address\")\n",
    "    subject: str = Field(description=\"Email subject line\")\n",
    "    body: str = Field(description=\"Email body content\")\n",
    "    customer_id: str | None = Field(default=None, description=\"Customer ID if known\")\n",
    "    ticket_id: str | None = Field(default=None, description=\"Related ticket ID if any\")\n",
    "\n",
    "# === Classification Model ===\n",
    "class ClassificationResult(BaseModel):\n",
    "    \"\"\"Result of email classification.\"\"\"\n",
    "    category: Literal[\"spam\", \"not_spam\", \"uncertain\"] = Field(description=\"Email category\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence score 0-1\")\n",
    "    reason: str = Field(description=\"Brief explanation of classification\")\n",
    "\n",
    "# === Draft Response Model ===\n",
    "class DraftResponse(BaseModel):\n",
    "    \"\"\"Draft reply to customer email.\"\"\"\n",
    "    subject: str = Field(description=\"Reply subject line\")\n",
    "    body: str = Field(description=\"Reply body\")\n",
    "    tone: Literal[\"formal\", \"friendly\", \"apologetic\"] = Field(description=\"Tone used\")\n",
    "    needs_review: bool = Field(default=False, description=\"Flag if needs human review\")\n",
    "\n",
    "# === Final Response Model ===\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"Final approved response.\"\"\"\n",
    "    classification: ClassificationResult\n",
    "    draft: DraftResponse | None = Field(default=None, description=\"Draft if not spam\")\n",
    "    review_notes: str | None = Field(default=None, description=\"Reviewer comments\")\n",
    "    approved: bool = Field(default=False, description=\"Whether approved to send\")\n",
    "\n",
    "print(\"âœ… Shared models defined: EmailInput, ClassificationResult, DraftResponse, FinalResponse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca66c9",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "\n",
    "Test emails used throughout the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d68e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample emails defined: LEGIT_EMAIL, SPAM_EMAIL, AMBIGUOUS_EMAIL\n"
     ]
    }
   ],
   "source": [
    "# === LEGITIMATE EMAIL ===\n",
    "LEGIT_EMAIL = EmailInput(\n",
    "    sender=\"sarah.chen@acmecorp.com\",\n",
    "    subject=\"Order #12345 - Delivery Issue\",\n",
    "    body=\"\"\"Hi Support Team,\n",
    "\n",
    "I placed order #12345 last week and the tracking shows it was delivered, \n",
    "but I never received the package. I've checked with my neighbors and the building \n",
    "concierge, but no one has seen it.\n",
    "\n",
    "This is urgent as the items were needed for a client presentation on Friday.\n",
    "Can you please help me locate the package or arrange a replacement?\n",
    "\n",
    "Thank you,\n",
    "Sarah Chen\n",
    "Account: ACME-7891\n",
    "\"\"\",\n",
    "    customer_id=\"CUST-7891\",\n",
    "    ticket_id=\"TKT-2024-001\"\n",
    ")\n",
    "\n",
    "# === SPAM EMAIL ===\n",
    "SPAM_EMAIL = EmailInput(\n",
    "    sender=\"winner@prize-notifications.biz\",\n",
    "    subject=\"ðŸŽ‰ CONGRATULATIONS! You've WON $1,000,000!!!\",\n",
    "    body=\"\"\"URGENT NOTIFICATION!!!\n",
    "\n",
    "You have been selected as the WINNER of our international lottery!\n",
    "To claim your $1,000,000 prize, simply send your bank details and \n",
    "a processing fee of $500 to unlock your winnings.\n",
    "\n",
    "ACT NOW - This offer expires in 24 HOURS!!!\n",
    "\n",
    "Click here to claim: http://totally-legit-prize.com/claim\n",
    "\"\"\",\n",
    "    customer_id=None,\n",
    "    ticket_id=None\n",
    ")\n",
    "\n",
    "# === AMBIGUOUS EMAIL ===\n",
    "AMBIGUOUS_EMAIL = EmailInput(\n",
    "    sender=\"j.smith@unknown-domain.net\",\n",
    "    subject=\"Partnership Opportunity\",\n",
    "    body=\"\"\"Hello,\n",
    "\n",
    "I found your company online and I'm interested in discussing a potential \n",
    "business partnership. We have a new product line that might complement your services.\n",
    "\n",
    "Can we schedule a call this week?\n",
    "\n",
    "Best,\n",
    "J. Smith\n",
    "\"\"\",\n",
    "    customer_id=None,\n",
    "    ticket_id=None\n",
    ")\n",
    "\n",
    "print(\"âœ… Sample emails defined: LEGIT_EMAIL, SPAM_EMAIL, AMBIGUOUS_EMAIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26154c1d",
   "metadata": {},
   "source": [
    "# 1. Basic Agent\n",
    "\n",
    "![Agent Components](images/agent-components.png)\n",
    "\n",
    "Create a support agent using `chat_client.as_agent()` with instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f96ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… support_agent created\n"
     ]
    }
   ],
   "source": [
    "# Create the core Support Agent - we'll enhance this throughout the notebook\n",
    "support_agent = chat_client.as_agent(\n",
    "    name=\"SupportAgent\",\n",
    "    instructions=\"\"\"You are a helpful customer support agent for an e-commerce company.\n",
    "Your job is to:\n",
    "1. Understand customer issues from their emails\n",
    "2. Draft professional, empathetic responses\n",
    "3. Provide clear next steps when possible\n",
    "\n",
    "Always be polite, acknowledge the customer's frustration, and offer concrete solutions.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… support_agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f5e7f",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Execute the agent with `agent.run()`. Returns an `AgentResponse` with `.text` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0324c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Draft Response:\n",
      "\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "Thank you for reaching out to us about your delivery issue. I understand how frustrating it must be to see that your order was marked as delivered but not receive it, especially with a client presentation coming up on Friday. \n",
      "\n",
      "I apologize for the inconvenience this has caused you. To assist in resolving this matter, I will start a trace with our carrier to locate your package. Additionally, I recommend checking with the shipping carrierâ€™s customer service as they might have more specific information about the delivery.\n",
      "\n",
      "In parallel, I can arrange for a replacement shipment to ensure you have your items in time for your presentation. Please confirm if you would like me to proceed with this option, and I will prioritize it to ensure timely delivery.\n",
      "\n",
      "Thank you for your patience while we work on this. I will keep you updated as soon as I receive any information.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "[Your Company]  \n",
      "[Contact Information]  \n"
     ]
    }
   ],
   "source": [
    "# Run the support agent on our legitimate email\n",
    "async def run_basic_agent():\n",
    "    prompt = f\"\"\"Please draft a response to this customer email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    result = await support_agent.run(prompt)\n",
    "    print(\"ðŸ“§ Draft Response:\\n\")\n",
    "    print(result.text)\n",
    "\n",
    "asyncio.run(run_basic_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9e31c",
   "metadata": {},
   "source": [
    "# 2. Streaming Responses\n",
    "\n",
    "Stream responses token-by-token using `agent.run_stream()` for real-time output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b03aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Streaming Draft Response:\n",
      "\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "Thank you for reaching out to us regarding your order #12345. I sincerely apologize for the inconvenience you are experiencing with your delivery. I understand how important it is to have your items for your upcoming client presentation, and I'm here to assist you with this issue.\n",
      "\n",
      "To help us locate your package, I will initiate an investigation with our shipping carrier to gather more information about the delivery. This process typically takes 24-48 hours. In the meantime, I recommend checking any areas where the package might have been left, such as different entrances or reception areas, if applicable.\n",
      "\n",
      "If the investigation confirms that the package cannot be located, we can arrange for a replacement to be sent out to you as soon as possible. I will keep you updated on the progress and will prioritize this matter so that you can receive your items in time for your presentation.\n",
      "\n",
      "Thank you for your patience, and please let me know if there is anything else I can assist you with in the meantime.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "[Your Company's Name]  \n",
      "[Your Contact Information]  \n"
     ]
    }
   ],
   "source": [
    "### Stream the response token by token using the SAME support_agent\n",
    "async def stream_support_response():\n",
    "    prompt = f\"\"\"Please draft a response to this customer email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    print(\"ðŸ“§ Streaming Draft Response:\\n\")\n",
    "    async for update in support_agent.run_stream(prompt):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming\n",
    "\n",
    "asyncio.run(stream_support_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54494e5c",
   "metadata": {},
   "source": [
    "# 3. Multi-Turn Conversations\n",
    "\n",
    "![Threads and Memory](images/threads-and-memory.png)\n",
    "\n",
    "Agents are stateless by default. Use **Threads** to maintain conversation context across turns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4aa94",
   "metadata": {},
   "source": [
    "## Using Threads\n",
    "\n",
    "Create a thread with `agent.get_new_thread()` and pass it to each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bc87f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: Summarize the issue\n",
      "--------------------------------------------------\n",
      "- The tracking for order #12345 indicates it was delivered, but Sarah has not received the package.\n",
      "- She has already checked with her neighbors and the building concierge with no luck finding the package.\n",
      "- Sarah urgently needs assistance to locate the package or arrange for a replacement due to an upcoming client presentation on Friday.\n",
      "\n",
      "Turn 2: Draft response with professional tone\n",
      "--------------------------------------------------\n",
      "Subject: Assistance with Your Order #12345\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "Thank you for reaching out to us regarding your recent order. I sincerely apologize for the inconvenience and frustration you are experiencing with the delivery of your package. I understand how important it is, especially with your client presentation approaching.\n",
      "\n",
      "Regarding the tracking information indicating delivery, it can sometimes lead to misunderstandings. I appreciate you taking the time to check with your neighbors and the building concierge. \n",
      "\n",
      "To assist you further, I will immediately investigate this matter with our shipping department and gather more information on the delivery status of your package. In the meantime, I will also prepare to escalate your request for a replacement in case we cannot locate your original order.\n",
      "\n",
      "Please allow me a moment to gather the necessary details, and I will get back to you as quickly as possible. Your patience is greatly appreciated during this process.\n",
      "\n",
      "Thank you for your understanding, and rest assured, I will do my best to resolve this issue for you promptly.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "[Your E-commerce Company]  \n",
      "[Contact Information]  \n"
     ]
    }
   ],
   "source": [
    "# Create a thread for multi-turn conversation\n",
    "thread = support_agent.get_new_thread()\n",
    "\n",
    "# Turn 1: Summarize the customer issue\n",
    "print(\"Turn 1: Summarize the issue\")\n",
    "print(\"-\" * 50)\n",
    "result1 = await support_agent.run(\n",
    "    f\"Summarize the key issues in this email in 2-3 bullet points:\\n\\n{LEGIT_EMAIL.body}\", \n",
    "    thread=thread\n",
    ")\n",
    "print(result1.text)\n",
    "print()\n",
    "\n",
    "# Turn 2: Draft a response (agent remembers the summary from Turn 1)\n",
    "print(\"Turn 2: Draft response with professional tone\")\n",
    "print(\"-\" * 50)\n",
    "result2 = await support_agent.run(\n",
    "    \"Now draft a professional response addressing each of those issues. Use a formal but empathetic tone.\",\n",
    "    thread=thread\n",
    ")\n",
    "print(result2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d5c10",
   "metadata": {},
   "source": [
    "# 4. Function Tools\n",
    "\n",
    "Extend agent capabilities by registering Python functions as tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d70fa",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Use the `@tool` decorator to expose functions to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963debc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Support tools defined: lookup_customer_sla, get_incident_status\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import tool\n",
    "# Simulated database of customer SLAs\n",
    "CUSTOMER_SLAS = {\n",
    "    \"CUST-7891\": {\"tier\": \"Premium\", \"response_time\": \"4 hours\", \"replacement_policy\": \"Free expedited replacement\"},\n",
    "    \"CUST-1234\": {\"tier\": \"Standard\", \"response_time\": \"24 hours\", \"replacement_policy\": \"Standard replacement\"},\n",
    "}\n",
    "\n",
    "# Simulated ticket database\n",
    "TICKET_STATUSES = {\n",
    "    \"TKT-2024-001\": {\"status\": \"Open\", \"priority\": \"High\", \"assigned_to\": \"Support Team\", \"last_update\": \"2024-01-15\"},\n",
    "    \"TKT-2024-002\": {\"status\": \"Resolved\", \"priority\": \"Low\", \"assigned_to\": \"Bot\", \"last_update\": \"2024-01-10\"},\n",
    "}\n",
    "\n",
    "@tool(name=\"lookup_customer_sla\", description=\"Look up a customer's SLA tier and policies\")\n",
    "def lookup_customer_sla(\n",
    "    customer_id: Annotated[str, Field(description=\"The customer ID to look up (e.g., CUST-7891)\")]\n",
    ") -> str:\n",
    "    \"\"\"Look up customer SLA information.\"\"\"\n",
    "    if customer_id in CUSTOMER_SLAS:\n",
    "        sla = CUSTOMER_SLAS[customer_id]\n",
    "        return f\"Customer {customer_id}: {sla['tier']} tier, {sla['response_time']} response time, {sla['replacement_policy']}\"\n",
    "    return f\"Customer {customer_id} not found in system.\"\n",
    "\n",
    "@tool(name=\"get_incident_status\", description=\"Get the current status of a support ticket\")\n",
    "def get_incident_status(\n",
    "    ticket_id: Annotated[str, Field(description=\"The ticket ID to check (e.g., TKT-2024-001)\")]\n",
    ") -> str:\n",
    "    \"\"\"Get ticket status information.\"\"\"\n",
    "    if ticket_id in TICKET_STATUSES:\n",
    "        ticket = TICKET_STATUSES[ticket_id]\n",
    "        return f\"Ticket {ticket_id}: Status={ticket['status']}, Priority={ticket['priority']}, Assigned to={ticket['assigned_to']}, Last update={ticket['last_update']}\"\n",
    "    return f\"Ticket {ticket_id} not found in system.\"\n",
    "\n",
    "print(\"âœ… Support tools defined: lookup_customer_sla, get_incident_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ee9eb",
   "metadata": {},
   "source": [
    "## Attach Tools to Agent\n",
    "\n",
    "Pass tools when creating the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363e4277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… support_agent_with_tools created\n"
     ]
    }
   ],
   "source": [
    "# Create support agent with tools\n",
    "support_agent_with_tools = chat_client.as_agent(\n",
    "    name=\"SupportAgentWithTools\",\n",
    "    instructions=\"\"\"You are a customer support agent with access to internal systems.\n",
    "When handling emails:\n",
    "1. Look up the customer's SLA tier to understand their service level\n",
    "2. Check ticket status if a ticket ID is mentioned\n",
    "3. Use this information to provide appropriate responses and set expectations\n",
    "\n",
    "Always be empathetic and use the customer's SLA tier to guide your response (e.g., Premium customers get expedited service).\"\"\",\n",
    "    tools=[lookup_customer_sla, get_incident_status]\n",
    ")\n",
    "\n",
    "print(\"âœ… support_agent_with_tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f461f75e",
   "metadata": {},
   "source": [
    "## Execute with Tools\n",
    "\n",
    "The agent autonomously decides when to invoke tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cff641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Response (with tool lookups):\n",
      "\n",
      "Subject: RE: Order #12345 - Delivery Issue\n",
      "\n",
      "Hi Sarah,\n",
      "\n",
      "Thank you for reaching out, and I understand how urgent this situation is, especially with your client presentation on Friday. \n",
      "\n",
      "I see that you are a Premium customer, which means you have a 4-hour response time for your inquiries and are eligible for a free expedited replacement. \n",
      "\n",
      "Iâ€™ve checked the status of your ticket (TKT-2024-001), and it is currently open with high priority. Our support team is already aware of your issue, and I will ensure that we expedite the process to locate your package or arrange for a replacement.\n",
      "\n",
      "I will follow up with you shortly with updates. In the meantime, if you have any other questions or need further assistance, please feel free to let me know.\n",
      "\n",
      "Thank you for your patience!\n",
      "\n",
      "Best,\n",
      "[Your Name]  \n",
      "Customer Support Team\n"
     ]
    }
   ],
   "source": [
    "# Test with the legitimate email that has customer_id and ticket_id\n",
    "prompt = f\"\"\"Handle this customer support email. Look up their SLA and ticket status first:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "Ticket ID: {LEGIT_EMAIL.ticket_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "\n",
    "result = await support_agent_with_tools.run(prompt)\n",
    "print(\"ðŸ“§ Response (with tool lookups):\\n\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530d0d1",
   "metadata": {},
   "source": [
    "# 5. Human-in-the-Loop Approval\n",
    "\n",
    "Require human confirmation before executing sensitive actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479786af",
   "metadata": {},
   "source": [
    "## Approval-Required Tool\n",
    "\n",
    "Set `approval_mode=\"always_require\"` on sensitive tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9cbdcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… approval_agent created with send_email_reply tool\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import ChatMessage, Content, Role\n",
    "\n",
    "# Tool that requires human approval before sending\n",
    "@tool(approval_mode=\"always_require\", name=\"send_email_reply\", description=\"Send an email reply to the customer. Requires human approval.\")\n",
    "def send_email_reply(\n",
    "    to: Annotated[str, Field(description=\"Recipient email address\")],\n",
    "    subject: Annotated[str, Field(description=\"Email subject\")],\n",
    "    body: Annotated[str, Field(description=\"Email body content\")]\n",
    ") -> str:\n",
    "    \"\"\"Send an email reply to the customer. Requires human approval.\"\"\"\n",
    "    # In production, this would actually send the email\n",
    "    return f\"âœ… Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "# Create agent with the approval-required tool\n",
    "approval_agent = chat_client.as_agent(\n",
    "    name=\"ApprovalSupportAgent\",\n",
    "    instructions=\"\"\"You are a customer support agent. After drafting a response, \n",
    "use the send_email_reply tool to send it. This will require human approval.\"\"\",\n",
    "    tools=[lookup_customer_sla, get_incident_status, send_email_reply]\n",
    ")\n",
    "\n",
    "print(\"âœ… approval_agent created with send_email_reply tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de90248",
   "metadata": {},
   "source": [
    "## Check for Pending Approvals\n",
    "\n",
    "Approval-required calls return `user_input_requests` instead of executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6063ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”’ APPROVAL REQUIRED!\n",
      "  Function: send_email_reply\n",
      "  Arguments: {\"to\":\"sarah.chen@acmecorp.com\",\"subject\":\"Re: Order #12345 - Delivery Issue\",\"body\":\"Hi Sarah,\\n\\nThank you for reaching out regarding your order #12345. I understand how important it is to have your items for the client presentation on Friday.\\n\\nSince the tracking shows that the package has been marked as delivered, I recommend checking again with your neighbors and concierge. However, given the urgency of your situation, we can expedite a replacement for you at no additional charge.\\n\\nPlease confirm if you'd like me to proceed with arranging a replacement, and I'll get that sorted out right away.\\n\\nThank you for your patience, and I look forward to hearing back from you soon!\\n\\nBest regards,\\n[Your Name]\\nCustomer Support Team\"}\n"
     ]
    }
   ],
   "source": [
    "# Ask the agent to handle and send a response\n",
    "prompt = f\"\"\"Handle this email and IMMEDIATELY use the send_email_reply tool to send a response. \n",
    "Do not ask for permission - just use the tool directly.\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "\n",
    "result = await approval_agent.run(prompt)\n",
    "\n",
    "# Check if approval is needed\n",
    "if result.user_input_requests:\n",
    "    print(\"ðŸ”’ APPROVAL REQUIRED!\")\n",
    "    for user_input_needed in result.user_input_requests:\n",
    "        print(f\"  Function: {user_input_needed.function_call.name}\")\n",
    "        print(f\"  Arguments: {user_input_needed.function_call.arguments}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No approval requested - agent didn't call the tool\")\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e80ab2",
   "metadata": {},
   "source": [
    "## Grant Approval\n",
    "\n",
    "Respond with `to_function_approval_response(True/False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa70478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Approval ---\n",
      "\n",
      "âœ… Human approved: True\n",
      "\n",
      "ðŸ“Š Final Result:\n",
      "I have successfully sent the response to Sarah Chen regarding her delivery issue for order #12345. If you need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Handling Approval ---\\n\")\n",
    "\n",
    "# Provide approval and continue the conversation\n",
    "if result.user_input_requests:\n",
    "    user_input_needed = result.user_input_requests[0]\n",
    "    \n",
    "    # Simulate human approval (in production, this would be interactive)\n",
    "    user_approval = True\n",
    "    print(f\"âœ… Human approved: {user_approval}\\n\")\n",
    "    \n",
    "    # Create approval response message\n",
    "    approval_message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[user_input_needed.to_function_approval_response(user_approval)]\n",
    "    )\n",
    "    \n",
    "    # Continue with approval\n",
    "    final_result = await approval_agent.run([\n",
    "        prompt,\n",
    "        ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
    "        approval_message\n",
    "    ])\n",
    "    print(f\"ðŸ“Š Final Result:\\n{final_result.text}\")\n",
    "else:\n",
    "    print(\"âŒ No approval was requested in the previous cell.\")\n",
    "    print(\"   The agent needs to call the send_email_reply tool to trigger approval.\")\n",
    "    print(\"   Re-run the previous cell to try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbefd9d",
   "metadata": {},
   "source": [
    "# 6. Middleware\n",
    "\n",
    "Intercept agent execution for logging, metrics, and observability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8829240",
   "metadata": {},
   "source": [
    "## Define Middleware\n",
    "\n",
    "Middleware wraps execution with `context` and `next` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae080f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Middleware defined: logging_agent_middleware, logging_function_middleware\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Awaitable\n",
    "from agent_framework import AgentRunContext, FunctionInvocationContext\n",
    "import time\n",
    "\n",
    "async def logging_agent_middleware(\n",
    "    context: AgentRunContext,\n",
    "    next: Callable[[AgentRunContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Log agent execution with timing.\"\"\"\n",
    "    print(f\"ðŸš€ Agent starting... ({len(context.messages)} message(s))\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    await next(context)  # Continue to agent execution\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Agent finished in {elapsed:.2f}s\")\n",
    "\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Log function tool calls.\"\"\"\n",
    "    print(f\"  ðŸ“ž Calling: {context.function.name}({context.arguments})\")\n",
    "    \n",
    "    await next(context)\n",
    "    \n",
    "    print(f\"  ðŸ“¤ Result: {context.result[:100]}...\" if len(str(context.result)) > 100 else f\"  ðŸ“¤ Result: {context.result}\")\n",
    "\n",
    "print(\"âœ… Middleware defined: logging_agent_middleware, logging_function_middleware\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e9a62",
   "metadata": {},
   "source": [
    "## Attach Middleware\n",
    "\n",
    "Pass middleware list when creating the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92c1554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Agent starting... (1 message(s))\n",
      "  ðŸ“ž Calling: lookup_customer_sla(customer_id='CUST-7891')\n",
      "  ðŸ“¤ Result: Customer CUST-7891: Premium tier, 4 hours response time, Free expedited replacement\n",
      "  ðŸ“ž Calling: get_incident_status(ticket_id='TKT-2024-001')\n",
      "  ðŸ“¤ Result: Ticket TKT-2024-001: Status=Open, Priority=High, Assigned to=Support Team, Last update=2024-01-15\n",
      "âœ… Agent finished in 3.17s\n",
      "\n",
      "ðŸ’¬ Response: Here are the details you requested:\n",
      "\n",
      "**SLA for Customer CUST-7891:**\n",
      "- Tier: Premium\n",
      "- Response Time: 4 hours\n",
      "- Policy: Free expedited replacement\n",
      "\n",
      "**Status of Ticket TKT-2024-001:**\n",
      "- Status: Open\n",
      "- Priority: High\n",
      "- Assigned to: Support Team\n",
      "- Last Update: January 15, 2024\n",
      "\n",
      "If you have any further questions or need assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Create agent with middleware for logging\n",
    "middleware_agent = chat_client.as_agent(\n",
    "    name=\"LoggingSupportAgent\",\n",
    "    instructions=\"You are a support agent. Look up customer information when handling requests.\",\n",
    "    tools=[lookup_customer_sla, get_incident_status],\n",
    "    middleware=[logging_agent_middleware, logging_function_middleware]\n",
    ")\n",
    "\n",
    "# Test - you'll see logs for agent and function calls\n",
    "prompt = f\"Check the SLA for customer {LEGIT_EMAIL.customer_id} and ticket status for {LEGIT_EMAIL.ticket_id}\"\n",
    "result = await middleware_agent.run(prompt)\n",
    "print(f\"\\nðŸ’¬ Response: {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffbde4",
   "metadata": {},
   "source": [
    "# 7. Agent Memory\n",
    "\n",
    "Persist context across calls using a `ContextProvider`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ced48",
   "metadata": {},
   "source": [
    "## Preferences Model\n",
    "\n",
    "Define what to remember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3468ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SupportPreferences model defined\n"
     ]
    }
   ],
   "source": [
    "class SupportPreferences(BaseModel):\n",
    "    \"\"\"User preferences for support interactions.\"\"\"\n",
    "    name: str | None = None\n",
    "    preferred_language: Literal[\"English\", \"Hebrew\", \"Spanish\"] = \"English\"\n",
    "    preferred_tone: Literal[\"formal\", \"friendly\", \"brief\"] = \"formal\"\n",
    "\n",
    "print(\"âœ… SupportPreferences model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdd4af",
   "metadata": {},
   "source": [
    "## Implement ContextProvider\n",
    "\n",
    "Two methods: `invoking` (inject context before calls) and `invoked` (extract state after calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "082eefb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SupportMemory ContextProvider defined\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import MutableSequence, Sequence\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import ContextProvider, Context, ChatAgent, ChatOptions\n",
    "\n",
    "\n",
    "class SupportMemory(ContextProvider):\n",
    "    \"\"\"Memory that tracks user preferences for support interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_client, preferences: SupportPreferences | None = None, **kwargs: Any):\n",
    "        \"\"\"Create the memory.\n",
    "        \n",
    "        Args:\n",
    "            chat_client: The chat client to use for extracting structured data\n",
    "            preferences: Optional initial preferences\n",
    "            **kwargs: Additional keyword arguments for deserialization\n",
    "        \"\"\"\n",
    "        self._chat_client = chat_client\n",
    "        if preferences:\n",
    "            self.preferences = preferences\n",
    "        elif kwargs:\n",
    "            self.preferences = SupportPreferences.model_validate(kwargs)\n",
    "        else:\n",
    "            self.preferences = SupportPreferences()\n",
    "    \n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        invoke_exception: Exception | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Extract preferences from user messages after each call.\"\"\"\n",
    "        # Ensure request_messages is a list\n",
    "        messages_list = [request_messages] if isinstance(request_messages, ChatMessage) else list(request_messages)\n",
    "        \n",
    "        # Check if we have user messages\n",
    "        user_messages = [msg for msg in messages_list if msg.role.value == \"user\"]\n",
    "        \n",
    "        if user_messages:\n",
    "            try:\n",
    "                # Use the chat client to extract structured information\n",
    "                # NOTE: Use `options=` not `chat_options=`\n",
    "                result = await self._chat_client.get_response(\n",
    "                    messages=messages_list,\n",
    "                    options=ChatOptions(\n",
    "                        instructions=(\n",
    "                            \"Extract the user's name, preferred tone (formal/friendly/brief), \"\n",
    "                            \"and preferred language (English/Hebrew/Spanish) from the messages if present. \"\n",
    "                            \"If not present, return None for that field.\"\n",
    "                        ),\n",
    "                        response_format=SupportPreferences,\n",
    "                    ),\n",
    "                )\n",
    "                \n",
    "                # result.value should now be a SupportPreferences instance\n",
    "                extracted = result.value\n",
    "                \n",
    "                # Update preferences with extracted data\n",
    "                if extracted and isinstance(extracted, SupportPreferences):\n",
    "                    if self.preferences.name is None and extracted.name:\n",
    "                        self.preferences.name = extracted.name\n",
    "                        print(f\"   ðŸ§  Memory updated: name = {extracted.name}\")\n",
    "                    \n",
    "                    if extracted.preferred_tone != \"formal\":  # formal is default\n",
    "                        self.preferences.preferred_tone = extracted.preferred_tone\n",
    "                        print(f\"   ðŸ§  Memory updated: tone = {extracted.preferred_tone}\")\n",
    "                    \n",
    "                    if extracted.preferred_language != \"English\":  # English is default\n",
    "                        self.preferences.preferred_language = extracted.preferred_language\n",
    "                        print(f\"   ðŸ§  Memory updated: language = {extracted.preferred_language}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ Failed to extract preferences: {e}\")\n",
    "    \n",
    "    async def invoking(self, messages: ChatMessage | MutableSequence[ChatMessage], **kwargs: Any) -> Context:\n",
    "        \"\"\"Provide preference context before each agent call.\"\"\"\n",
    "        instructions: list[str] = []\n",
    "        \n",
    "        if self.preferences.name:\n",
    "            instructions.append(f\"The user's name is {self.preferences.name}. Address them by name.\")\n",
    "        \n",
    "        instructions.append(f\"Respond in {self.preferences.preferred_language}.\")\n",
    "        instructions.append(f\"Use a {self.preferences.preferred_tone} tone.\")\n",
    "        \n",
    "        return Context(instructions=\" \".join(instructions))\n",
    "    \n",
    "    def serialize(self) -> str:\n",
    "        \"\"\"Serialize for persistence.\"\"\"\n",
    "        return self.preferences.model_dump_json()\n",
    "\n",
    "print(\"âœ… SupportMemory ContextProvider defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d6fd8",
   "metadata": {},
   "source": [
    "## Test Memory\n",
    "\n",
    "The agent automatically extracts and applies preferences across turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "417d9431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: User introduction\n",
      "--------------------------------------------------\n",
      "   ðŸ§  Memory updated: name = David\n",
      "   ðŸ§  Memory updated: tone = friendly\n",
      "Agent: Hello, David! How may I assist you today?\n",
      "\n",
      "Turn 2: Setting preference\n",
      "--------------------------------------------------\n",
      "   ðŸ§  Memory updated: tone = brief\n",
      "Agent: Got it, David! I'll keep it short and casual for you. What do you need help with?\n",
      "\n",
      "Turn 3: Question with preferences applied\n",
      "--------------------------------------------------\n",
      "   ðŸ§  Memory updated: tone = brief\n",
      "Agent: Hi David! Our return policy typically allows for returns within 30 days of purchase, provided the item is unused and in its original packaging. However, I recommend checking the specific details on our website or your receipt, as policies can vary by product. Let me know if you need more help!\n",
      "\n",
      "ðŸ§  Memory State (tracked by ContextProvider):\n",
      "   Name: David\n",
      "   Language: English\n",
      "   Tone: brief\n"
     ]
    }
   ],
   "source": [
    "# Create the memory provider using the existing chat_client\n",
    "support_memory = SupportMemory(chat_client)\n",
    "\n",
    "# Create the agent with memory\n",
    "memory_agent = ChatAgent(\n",
    "    name=\"MemorySupportAgent\",\n",
    "    instructions=\"You are a friendly support agent. Adapt your responses based on user preferences.\",\n",
    "    chat_client=chat_client,\n",
    "    context_provider=support_memory,\n",
    ")\n",
    "\n",
    "# Turn 1: User introduces themselves\n",
    "print(\"Turn 1: User introduction\")\n",
    "print(\"-\" * 50)\n",
    "result1 = await memory_agent.run(\"Hi, my name is David\")\n",
    "print(f\"Agent: {result1.text}\\n\")\n",
    "\n",
    "# Turn 2: User sets preference\n",
    "print(\"Turn 2: Setting preference\")\n",
    "print(\"-\" * 50)\n",
    "result2 = await memory_agent.run(\"Please keep responses brief and casual\")\n",
    "print(f\"Agent: {result2.text}\\n\")\n",
    "\n",
    "# Turn 3: Ask a question - memory should apply name and brief tone\n",
    "print(\"Turn 3: Question with preferences applied\")\n",
    "print(\"-\" * 50)\n",
    "result3 = await memory_agent.run(\"What's your return policy?\")\n",
    "print(f\"Agent: {result3.text}\\n\")\n",
    "\n",
    "# Check memory state - access the original support_memory object directly\n",
    "print(\"ðŸ§  Memory State (tracked by ContextProvider):\")\n",
    "print(f\"   Name: {support_memory.preferences.name}\")\n",
    "print(f\"   Language: {support_memory.preferences.preferred_language}\")\n",
    "print(f\"   Tone: {support_memory.preferences.preferred_tone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429fcad",
   "metadata": {},
   "source": [
    "# 8. Sequential Workflows\n",
    "\n",
    "![Sequential Workflow](images/sequential-workflow.png)\n",
    "\n",
    "Chain multiple agents/executors in sequence: Classify â†’ Draft â†’ Review.\n",
    "\n",
    "**When to Use:**\n",
    "- Tasks with clear, ordered steps (e.g., parse â†’ validate â†’ transform)\n",
    "- When each step's output is the next step's input\n",
    "- Processing pipelines where order matters\n",
    "\n",
    "**When NOT to Use:**\n",
    "- Steps can run independently (use Concurrent instead)\n",
    "- Dynamic routing needed (use Branching instead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6274db5",
   "metadata": {},
   "source": [
    "## Core Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Executor** | Unit of work (`@executor` or class with `@handler`) |\n",
    "| **WorkflowBuilder** | Connects executors with `add_edge()` |\n",
    "| `ctx.send_message()` | Pass data to next executor |\n",
    "| `ctx.yield_output()` | Return final result |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80541f",
   "metadata": {},
   "source": [
    "## Define Executors\n",
    "\n",
    "Create agent executors for classification, writing, and review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "276a9eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow agents defined: classifier, writer, reviewer\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Never\n",
    "from agent_framework import (\n",
    "    WorkflowBuilder, WorkflowContext, WorkflowOutputEvent,\n",
    "    Executor, executor, handler, AgentExecutor, AgentExecutorRequest, AgentExecutorResponse\n",
    ")\n",
    "\n",
    "# === CLASSIFIER AGENT ===\n",
    "classifier_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Classifier\",\n",
    "        instructions=\"\"\"Classify incoming emails. Return JSON with:\n",
    "- category: \"spam\", \"not_spam\", or \"uncertain\"\n",
    "- confidence: float 0-1\n",
    "- reason: brief explanation\"\"\",\n",
    "        response_format=ClassificationResult,\n",
    "    ),\n",
    "    id=\"classifier\",\n",
    ")\n",
    "\n",
    "# === DRAFT WRITER AGENT ===\n",
    "writer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"DraftWriter\",\n",
    "        instructions=\"\"\"Draft professional support responses. Return JSON with:\n",
    "- subject: reply subject line\n",
    "- body: reply body\n",
    "- tone: \"formal\", \"friendly\", or \"apologetic\"\n",
    "- needs_review: true if sensitive or complex\"\"\",\n",
    "        response_format=DraftResponse,\n",
    "    ),\n",
    "    id=\"writer\",\n",
    ")\n",
    "\n",
    "# === REVIEWER AGENT ===\n",
    "reviewer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Reviewer\",\n",
    "        instructions=\"\"\"Review draft responses for quality. Check:\n",
    "- Professionalism and tone\n",
    "- Accuracy of information\n",
    "- Completeness\n",
    "Return approval decision with notes.\"\"\",\n",
    "    ),\n",
    "    id=\"reviewer\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Workflow agents defined: classifier, writer, reviewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f78d8",
   "metadata": {},
   "source": [
    "## Build & Run\n",
    "\n",
    "Connect executors with `add_edge()` and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b511c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Processing email through workflow: Classify â†’ Draft â†’ Review\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ… [classifier]:\n",
      "   {\n",
      "  \"category\": \"not_spam\",\n",
      "  \"confidence\": 0.95,\n",
      "  \"reason\": \"The email is a legitimate support request regarding a delivery issue from a customer, containing specific details relevant to an order.\"\n",
      "}...\n",
      "\n",
      "âœ… [writer]:\n",
      "   {\n",
      "  \"subject\": \"Assistance with Your Order #12345 - Delivery Issue\",\n",
      "  \"body\": \"Dear Ms. Chen,\\n\\nThank you for reaching out to us regarding the delivery issue with your recent order #12345. I understand the urgency of the situation, especially with your client presentation approaching on Friday.\\n\\...\n",
      "\n",
      "âœ… [reviewer]:\n",
      "   Approval Decision: **Approved**\n",
      "\n",
      "Notes:\n",
      "- The response maintains a professional and empathetic tone, recognizing the urgency of the customer's situation while reassuring them that their issue is being addressed.\n",
      "- It accurately acknowledges the details provided by the customer regarding the order nu...\n"
     ]
    }
   ],
   "source": [
    "# Build sequential workflow\n",
    "sequential_support_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(classifier_agent)\n",
    "    .add_edge(classifier_agent, writer_agent)\n",
    "    .add_edge(writer_agent, reviewer_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Run with legitimate email\n",
    "async def run_sequential_workflow():\n",
    "    email_prompt = f\"\"\"Process this support email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ“§ Processing email through workflow: Classify â†’ Draft â†’ Review\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    request = AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=email_prompt)],\n",
    "        should_respond=True\n",
    "    )\n",
    "    \n",
    "    from agent_framework._workflows._events import ExecutorCompletedEvent\n",
    "    \n",
    "    async for event in sequential_support_workflow.run_stream(request):\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"\\nâœ… [{event.executor_id}]:\")\n",
    "                print(f\"   {data.agent_response.text[:300]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"\\nðŸŽ¯ FINAL OUTPUT:\")\n",
    "            if isinstance(event.data, list) and event.data:\n",
    "                final = event.data[0]\n",
    "                if hasattr(final, 'agent_response'):\n",
    "                    print(final.agent_response.text)\n",
    "\n",
    "await run_sequential_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37a59d",
   "metadata": {},
   "source": [
    "# 9. Branching Logic\n",
    "\n",
    "Route execution based on conditions: Spam â†’ Block, NotSpam â†’ Draft, Uncertain â†’ Review.\n",
    "\n",
    "**When to Use:**\n",
    "- Different paths based on classification or conditions\n",
    "- Error handling with fallback routes\n",
    "- Multi-way routing (switch-case patterns)\n",
    "\n",
    "**When NOT to Use:**\n",
    "- All items follow the same path (use Sequential)\n",
    "- Need parallel execution of branches (use Fan-Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec9cf6",
   "metadata": {},
   "source": [
    "## Routing Patterns\n",
    "\n",
    "| Pattern | Use Case |\n",
    "|---------|----------|\n",
    "| **Conditional Edge** | Binary if/else |\n",
    "| **Switch-Case** | Multi-way routing |\n",
    "| **Multi-Selection** | Dynamic fan-out |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60db70",
   "metadata": {},
   "source": [
    "## Define Branch Handlers\n",
    "\n",
    "Create handlers for each classification outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38082206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Branching executors defined\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from uuid import uuid4\n",
    "from agent_framework import Case, Default\n",
    "\n",
    "# Internal payload for routing\n",
    "@dataclass\n",
    "class ClassifiedEmail:\n",
    "    email_id: str\n",
    "    category: str  # spam, not_spam, uncertain\n",
    "    confidence: float\n",
    "    reason: str\n",
    "    original_content: str\n",
    "\n",
    "# Shared state keys\n",
    "EMAIL_KEY = \"current_email\"\n",
    "\n",
    "# Helper to extract JSON from markdown code blocks\n",
    "def extract_json(text: str) -> str:\n",
    "    \"\"\"Extract JSON from text, stripping markdown code blocks if present.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text.strip()\n",
    "\n",
    "# Transform classification result to routable payload\n",
    "@executor(id=\"extract_classification\")\n",
    "async def extract_classification(response: Any, ctx: WorkflowContext[ClassifiedEmail]) -> None:\n",
    "    \"\"\"Extract classification from agent response for routing.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    \n",
    "    # Extract JSON (handles markdown code blocks)\n",
    "    json_text = extract_json(response.agent_response.text)\n",
    "    classification = ClassificationResult.model_validate_json(json_text)\n",
    "    \n",
    "    # Get original email from shared state\n",
    "    original_content = await ctx.get_shared_state(EMAIL_KEY) or \"Unknown\"\n",
    "    \n",
    "    payload = ClassifiedEmail(\n",
    "        email_id=str(uuid4()),\n",
    "        category=classification.category,\n",
    "        confidence=classification.confidence,\n",
    "        reason=classification.reason,\n",
    "        original_content=original_content\n",
    "    )\n",
    "    await ctx.send_message(payload)\n",
    "\n",
    "# Route conditions\n",
    "def is_spam(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"spam\"\n",
    "\n",
    "def is_not_spam(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"not_spam\"\n",
    "\n",
    "def is_uncertain(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"uncertain\"\n",
    "\n",
    "# Terminal handlers\n",
    "@executor(id=\"handle_spam\")\n",
    "async def handle_spam_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle spam: block and log.\"\"\"\n",
    "    await ctx.yield_output(f\"ðŸš« SPAM BLOCKED: {email.reason} (confidence: {email.confidence:.0%})\")\n",
    "\n",
    "@executor(id=\"handle_not_spam\")\n",
    "async def handle_not_spam_continue(email: ClassifiedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Handle not_spam: forward to writer.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to: {email.original_content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "@executor(id=\"finalize_draft\")\n",
    "async def finalize_draft(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Output the final draft.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    # Extract JSON (handles markdown code blocks)\n",
    "    json_text = extract_json(response.agent_response.text)\n",
    "    draft = DraftResponse.model_validate_json(json_text)\n",
    "    await ctx.yield_output(f\"âœ‰ï¸ DRAFT READY:\\nSubject: {draft.subject}\\n\\n{draft.body}\")\n",
    "\n",
    "@executor(id=\"handle_uncertain\")\n",
    "async def handle_uncertain_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle uncertain: flag for human review.\"\"\"\n",
    "    await ctx.yield_output(f\"âš ï¸ NEEDS HUMAN REVIEW: {email.reason} (confidence: {email.confidence:.0%})\\n\\nOriginal: {email.original_content[:200]}...\")\n",
    "\n",
    "print(\"âœ… Branching executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f06000",
   "metadata": {},
   "source": [
    "## Build Switch-Case Workflow\n",
    "\n",
    "Route based on classification result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "840d3b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Branching workflow built\n"
     ]
    }
   ],
   "source": [
    "# Store email and start classification\n",
    "@executor(id=\"start_classification\")\n",
    "async def start_classification(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Store email and send for classification.\"\"\"\n",
    "    await ctx.set_shared_state(EMAIL_KEY, email_text)\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Classify this email:\\n\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Build branching workflow\n",
    "branching_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(start_classification)\n",
    "    .add_edge(start_classification, classifier_agent)\n",
    "    .add_edge(classifier_agent, extract_classification)\n",
    "    # Switch-case routing\n",
    "    .add_switch_case_edge_group(\n",
    "        extract_classification,\n",
    "        [\n",
    "            Case(condition=is_spam, target=handle_spam_terminal),\n",
    "            Case(condition=is_not_spam, target=handle_not_spam_continue),\n",
    "            Default(target=handle_uncertain_terminal),  # Catches uncertain + unexpected\n",
    "        ],\n",
    "    )\n",
    "    # Continue not_spam path to draft\n",
    "    .add_edge(handle_not_spam_continue, writer_agent)\n",
    "    .add_edge(writer_agent, finalize_draft)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Branching workflow built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6f304",
   "metadata": {},
   "source": [
    "## Test Branching\n",
    "\n",
    "Run all three email types through the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59110839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“§ Testing LEGITIMATE email...\n",
      "--------------------------------------------------\n",
      "âœ‰ï¸ DRAFT READY:\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "\n",
      "Dear Ms. Chen,\n",
      "\n",
      "Thank you for contacting us regarding the issue with your order #12345. I sincerely apologize for the inconvenience this has caused, especially with your client presentation approaching on Friday.\n",
      "\n",
      "We are currently investigating the delivery status of your package. I appreciate your efforts in checking with your neighbors and the concierge. In the meantime, I will expedite this matter and ensure we provide you with a solution as quickly as possible, whether it is locating your package or arranging a replacement if necessary.\n",
      "\n",
      "Please rest assured that we are on it, and I will keep you updated throughout the process.\n",
      "\n",
      "Thank you for your understanding and patience.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "ACME Corporation\n",
      "\n",
      "ðŸ“§ Testing SPAM email...\n",
      "--------------------------------------------------\n",
      "ðŸš« SPAM BLOCKED: The email contains obvious signs of a lottery scam, requesting bank details and a processing fee, which is characteristic of fraudulent messages. (confidence: 99%)\n",
      "\n",
      "ðŸ“§ Testing AMBIGUOUS email...\n",
      "--------------------------------------------------\n",
      "âš ï¸ NEEDS HUMAN REVIEW: The email expresses interest in a partnership but comes from an unknown domain, which raises suspicion. It lacks specific details that could confirm its legitimacy. (confidence: 65%)\n",
      "\n",
      "Original: From: j.smith@unknown-domain.net\n",
      "Subject: Partnership Opportunity\n",
      "\n",
      "Hello,\n",
      "\n",
      "I found your company online and I'm interested in discussing a potential \n",
      "business partnership. We have a new product line th...\n"
     ]
    }
   ],
   "source": [
    "# Test all three paths\n",
    "async def test_branching():\n",
    "    test_cases = [\n",
    "        (\"LEGITIMATE\", LEGIT_EMAIL),\n",
    "        (\"SPAM\", SPAM_EMAIL),\n",
    "        (\"AMBIGUOUS\", AMBIGUOUS_EMAIL),\n",
    "    ]\n",
    "    \n",
    "    for label, email in test_cases:\n",
    "        print(f\"\\nðŸ“§ Testing {label} email...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        email_text = f\"From: {email.sender}\\nSubject: {email.subject}\\n\\n{email.body}\"\n",
    "        \n",
    "        async for event in branching_workflow.run_stream(email_text):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                print(event.data)\n",
    "\n",
    "await test_branching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ecb767",
   "metadata": {},
   "source": [
    "# 10. Fan-Out / Fan-In\n",
    "\n",
    "![Concurrent Workflow](images/concurrent-workflow.png)\n",
    "\n",
    "Process multiple paths in parallel and aggregate results.\n",
    "\n",
    "**When to Use:**\n",
    "- Independent tasks that can run concurrently\n",
    "- Aggregating results from multiple sources\n",
    "- Performance optimization through parallelization\n",
    "\n",
    "**When NOT to Use:**\n",
    "- Tasks have dependencies on each other\n",
    "- Order of execution matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e4e6",
   "metadata": {},
   "source": [
    "## Define Parallel Paths\n",
    "\n",
    "For long emails: respond AND summarize concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8e251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parallel processing executors defined\n"
     ]
    }
   ],
   "source": [
    "# Summary model\n",
    "class EmailSummary(BaseModel):\n",
    "    \"\"\"Concise email summary.\"\"\"\n",
    "    key_points: list[str] = Field(description=\"Main points from the email\")\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"Urgency level\")\n",
    "    action_required: str = Field(description=\"Primary action needed\")\n",
    "\n",
    "# Summarizer agent\n",
    "summarizer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Summarizer\",\n",
    "        instructions=\"\"\"Summarize emails concisely. Return JSON with:\n",
    "- key_points: list of main points\n",
    "- urgency: low/medium/high\n",
    "- action_required: primary action needed\"\"\",\n",
    "        response_format=EmailSummary,\n",
    "    ),\n",
    "    id=\"summarizer\",\n",
    ")\n",
    "\n",
    "# Threshold for \"long\" emails\n",
    "LONG_EMAIL_THRESHOLD = 200  # characters\n",
    "\n",
    "@dataclass\n",
    "class EnrichedEmail:\n",
    "    \"\"\"Email with metadata for routing.\"\"\"\n",
    "    email_id: str\n",
    "    content: str\n",
    "    is_long: bool\n",
    "    category: str\n",
    "\n",
    "# Selection function for multi-selection routing\n",
    "def select_parallel_paths(email: EnrichedEmail, target_ids: list[str]) -> list[str]:\n",
    "    \"\"\"Select paths based on email length.\"\"\"\n",
    "    # target_ids order: [respond_path, summarize_path]\n",
    "    respond_id, summarize_id = target_ids\n",
    "    \n",
    "    if email.is_long:\n",
    "        return [respond_id, summarize_id]  # Both paths in parallel\n",
    "    else:\n",
    "        return [respond_id]  # Only respond for short emails\n",
    "\n",
    "# Executors for parallel paths\n",
    "@executor(id=\"prepare_parallel\")\n",
    "async def prepare_parallel(classified: ClassifiedEmail, ctx: WorkflowContext[EnrichedEmail]) -> None:\n",
    "    \"\"\"Prepare email for parallel processing.\"\"\"\n",
    "    enriched = EnrichedEmail(\n",
    "        email_id=classified.email_id,\n",
    "        content=classified.original_content,\n",
    "        is_long=len(classified.original_content) > LONG_EMAIL_THRESHOLD,\n",
    "        category=classified.category\n",
    "    )\n",
    "    await ctx.send_message(enriched)\n",
    "\n",
    "@executor(id=\"respond_path\")\n",
    "async def respond_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Send to writer for response.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email.content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "@executor(id=\"summarize_path\")\n",
    "async def summarize_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Send to summarizer.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email.content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Aggregator to combine parallel results\n",
    "class ParallelAggregator(Executor):\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"parallel_aggregator\")\n",
    "    \n",
    "    @handler\n",
    "    async def aggregate(self, results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
    "        \"\"\"Combine response and summary.\"\"\"\n",
    "        output_parts = []\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, AgentExecutorResponse):\n",
    "                try:\n",
    "                    draft = DraftResponse.model_validate_json(result.agent_response.text)\n",
    "                    output_parts.append(f\"ðŸ“§ DRAFT RESPONSE:\\nSubject: {draft.subject}\\n{draft.body}\")\n",
    "                except:\n",
    "                    try:\n",
    "                        summary = EmailSummary.model_validate_json(result.agent_response.text)\n",
    "                        points = \"\\n\".join(f\"  â€¢ {p}\" for p in summary.key_points)\n",
    "                        output_parts.append(f\"ðŸ“‹ SUMMARY:\\n{points}\\nUrgency: {summary.urgency}\\nAction: {summary.action_required}\")\n",
    "                    except:\n",
    "                        output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
    "        \n",
    "        await ctx.yield_output(\"\\n\\n\" + \"=\"*40 + \"\\n\\n\".join(output_parts))\n",
    "\n",
    "aggregator = ParallelAggregator()\n",
    "\n",
    "print(\"âœ… Parallel processing executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ef984",
   "metadata": {},
   "source": [
    "## Build Fan-Out/Fan-In Workflow\n",
    "\n",
    "Short emails â†’ respond only. Long emails â†’ respond + summarize in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e887adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fan-out/fan-in workflow built\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import WorkflowBuilder\n",
    "from agent_framework._workflows._events import ExecutorCompletedEvent\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "LONG_EMAIL_THRESHOLD = 200  # Characters\n",
    "\n",
    "# Start executor - entry point stores email and passes it forward\n",
    "@executor(id=\"fanout_start\")\n",
    "async def fanout_start(email_text: str, ctx: WorkflowContext[str]) -> None:\n",
    "    \"\"\"Entry point: store email length, forward email text.\"\"\"\n",
    "    # Store email length in shared state for selection\n",
    "    await ctx.set_shared_state(\"email_length\", len(email_text))\n",
    "    # Store workflow start time\n",
    "    await ctx.set_shared_state(\"workflow_start_time\", time.time())\n",
    "    await ctx.send_message(email_text)\n",
    "\n",
    "# Selection function that uses shared state\n",
    "def fanout_select_paths(email_text: str, target_ids: list[str]) -> list[str]:\n",
    "    \"\"\"Select paths based on email length (stored in text).\"\"\"\n",
    "    # The email_text is still the raw string at this point\n",
    "    if len(email_text) > LONG_EMAIL_THRESHOLD:\n",
    "        return target_ids  # Both paths for long emails\n",
    "    return [target_ids[0]]  # Only response path for short emails\n",
    "\n",
    "# Response path preparer with timing\n",
    "@executor(id=\"fanout_respond_prep\")\n",
    "async def fanout_respond_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Prepare email for writer agent.\"\"\"\n",
    "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
    "    start_time = time.time()\n",
    "    elapsed = start_time - workflow_start\n",
    "    print(f\"   â±ï¸  [+{elapsed:.2f}s] ðŸ“ RESPONSE PATH started\")\n",
    "    \n",
    "    await ctx.set_shared_state(\"response_start_time\", start_time)\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Summary path preparer with timing\n",
    "@executor(id=\"fanout_summarize_prep\")\n",
    "async def fanout_summarize_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Prepare email for summarizer agent.\"\"\"\n",
    "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
    "    start_time = time.time()\n",
    "    elapsed = start_time - workflow_start\n",
    "    print(f\"   â±ï¸  [+{elapsed:.2f}s] ðŸ“‹ SUMMARY PATH started\")\n",
    "    \n",
    "    await ctx.set_shared_state(\"summary_start_time\", start_time)\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Capture completion time immediately after writer finishes\n",
    "@executor(id=\"capture_writer_completion\")\n",
    "async def capture_writer_completion(result: Any, ctx: WorkflowContext[Any]) -> None:\n",
    "    \"\"\"Capture writer completion time.\"\"\"\n",
    "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
    "    response_start = await ctx.get_shared_state(\"response_start_time\")\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_from_start = end_time - workflow_start\n",
    "    duration = end_time - response_start\n",
    "    print(f\"   â±ï¸  [+{elapsed_from_start:.2f}s] âœ… RESPONSE PATH completed ({duration:.2f}s)\")\n",
    "    \n",
    "    await ctx.set_shared_state(\"response_end_time\", end_time)\n",
    "    await ctx.send_message(result)\n",
    "\n",
    "# Capture completion time immediately after summarizer finishes\n",
    "@executor(id=\"capture_summarizer_completion\")\n",
    "async def capture_summarizer_completion(result: Any, ctx: WorkflowContext[Any]) -> None:\n",
    "    \"\"\"Capture summarizer completion time.\"\"\"\n",
    "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
    "    summary_start = await ctx.get_shared_state(\"summary_start_time\")\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_from_start = end_time - workflow_start\n",
    "    duration = end_time - summary_start\n",
    "    print(f\"   â±ï¸  [+{elapsed_from_start:.2f}s] âœ… SUMMARY PATH completed ({duration:.2f}s)\")\n",
    "    \n",
    "    await ctx.set_shared_state(\"summary_end_time\", end_time)\n",
    "    await ctx.send_message(result)\n",
    "\n",
    "# Aggregator - combines results from parallel paths with timing\n",
    "@executor(id=\"fanout_aggregator\")\n",
    "async def fanout_aggregator(results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Combine response and summary results with timing information.\"\"\"\n",
    "    response_start = await ctx.get_shared_state(\"response_start_time\")\n",
    "    summary_start = await ctx.get_shared_state(\"summary_start_time\")\n",
    "    response_end = await ctx.get_shared_state(\"response_end_time\")\n",
    "    summary_end = await ctx.get_shared_state(\"summary_end_time\")\n",
    "    \n",
    "    output_parts = []\n",
    "    response_time = None\n",
    "    summary_time = None\n",
    "    \n",
    "    # Calculate durations from stored times\n",
    "    if response_start and response_end:\n",
    "        response_time = response_end - response_start\n",
    "    if summary_start and summary_end:\n",
    "        summary_time = summary_end - summary_start\n",
    "    \n",
    "    for result in results:\n",
    "        if isinstance(result, AgentExecutorResponse):\n",
    "            try:\n",
    "                draft = DraftResponse.model_validate_json(extract_json(result.agent_response.text))\n",
    "                output_parts.append(\n",
    "                    f\"ðŸ“¬ RESPONSE (completed in {response_time:.2f}s):\\n\"\n",
    "                    f\"Subject: {draft.subject}\\n{draft.body}\"\n",
    "                )\n",
    "            except:\n",
    "                try:\n",
    "                    summary = EmailSummary.model_validate_json(extract_json(result.agent_response.text))\n",
    "                    points = \"\\n\".join(f\"  â€¢ {p}\" for p in summary.key_points)\n",
    "                    output_parts.append(\n",
    "                        f\"ðŸ“‹ SUMMARY (completed in {summary_time:.2f}s):\\n\"\n",
    "                        f\"{points}\\n\"\n",
    "                        f\"Urgency: {summary.urgency}\\n\"\n",
    "                        f\"Action: {summary.action_required}\"\n",
    "                    )\n",
    "                except:\n",
    "                    output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
    "    \n",
    "    # Calculate overlap to show parallelization\n",
    "    if response_time and summary_time:\n",
    "        total_sequential = response_time + summary_time\n",
    "        total_parallel = max(response_time, summary_time)\n",
    "        time_saved = total_sequential - total_parallel\n",
    "        output_parts.append(\n",
    "            f\"\\nâš¡ PARALLEL EXECUTION BENEFIT:\\n\"\n",
    "            f\"   Sequential time: {total_sequential:.2f}s\\n\"\n",
    "            f\"   Parallel time: {total_parallel:.2f}s\\n\"\n",
    "            f\"   Time saved: {time_saved:.2f}s ({time_saved/total_sequential*100:.1f}%)\"\n",
    "        )\n",
    "    \n",
    "    await ctx.yield_output(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join(output_parts))\n",
    "\n",
    "# Build the fan-out workflow\n",
    "# Pattern: start -> [fanout to preparers] -> [agents] -> [capture timing] -> aggregator\n",
    "fanout_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(fanout_start)\n",
    "    # Fan-out from start directly to path preparers based on email length\n",
    "    .add_multi_selection_edge_group(\n",
    "        fanout_start,\n",
    "        targets=[fanout_respond_prep, fanout_summarize_prep],\n",
    "        selection_func=fanout_select_paths,\n",
    "    )\n",
    "    # Each preparer sends to its agent\n",
    "    .add_edge(fanout_respond_prep, writer_agent)\n",
    "    .add_edge(fanout_summarize_prep, summarizer_agent)\n",
    "    # Capture completion times immediately after each agent\n",
    "    .add_edge(writer_agent, capture_writer_completion)\n",
    "    .add_edge(summarizer_agent, capture_summarizer_completion)\n",
    "    # Fan-in: collect all results\n",
    "    .add_fan_in_edges([capture_writer_completion, capture_summarizer_completion], fanout_aggregator)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Fan-out/fan-in workflow built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b962d58",
   "metadata": {},
   "source": [
    "## Test Parallel Execution\n",
    "\n",
    "Long emails trigger both response and summary paths concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7492286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Testing LONG email (468 chars > 200 threshold)\n",
      "Expected: Response AND Summary in parallel\n",
      "\n",
      "------------------------------------------------------------\n",
      "   â±ï¸  [+0.00s] ðŸ“ RESPONSE PATH started\n",
      "   â±ï¸  [+0.00s] ðŸ“‹ SUMMARY PATH started\n",
      "   â±ï¸  [+3.82s] âœ… SUMMARY PATH completed (3.82s)\n",
      "   â±ï¸  [+3.83s] âœ… RESPONSE PATH completed (3.83s)\n",
      "\n",
      "\n",
      "==================================================ðŸ“¬ RESPONSE (completed in 3.83s):\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "Dear Ms. Chen,\n",
      "\n",
      "Thank you for reaching out regarding your order #12345. I understand how important this order is for your upcoming client presentation, and I apologize for the inconvenience you've experienced with the delivery.\n",
      "\n",
      "I will investigate this matter immediately. Please allow me some time to check with our shipping department and track down the package. In the event we cannot locate it, I will ensure we arrange a replacement for you as soon as possible so that you have your items in time for your presentation on Friday.\n",
      "\n",
      "I appreciate your patience and understanding during this process. I will keep you updated with any information I gather.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "ACME Corporation\n",
      "\n",
      "ðŸ“‹ SUMMARY (completed in 3.82s):\n",
      "  â€¢ Order #12345 was placed last week.\n",
      "  â€¢ Tracking indicates the package was delivered, but Sarah has not received it.\n",
      "  â€¢ She checked with neighbors and the building concierge with no success.\n",
      "  â€¢ The package is needed urgently for a client presentation on Friday.\n",
      "  â€¢ Sarah requests help to locate the package or arrange a replacement.\n",
      "Urgency: high\n",
      "Action: Locate the package or arrange a replacement\n",
      "\n",
      "\n",
      "âš¡ PARALLEL EXECUTION BENEFIT:\n",
      "   Sequential time: 7.65s\n",
      "   Parallel time: 3.83s\n",
      "   Time saved: 3.82s (49.9%)\n"
     ]
    }
   ],
   "source": [
    "# Test with long legitimate email\n",
    "async def test_fanout():\n",
    "    email_text = f\"From: {LEGIT_EMAIL.sender}\\nSubject: {LEGIT_EMAIL.subject}\\n\\n{LEGIT_EMAIL.body}\"\n",
    "    \n",
    "    print(f\"ðŸ“§ Testing LONG email ({len(email_text)} chars > {LONG_EMAIL_THRESHOLD} threshold)\")\n",
    "    print(\"Expected: Response AND Summary in parallel\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    async for event in fanout_workflow.run_stream(email_text):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(event.data)\n",
    "\n",
    "await test_fanout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a7439",
   "metadata": {},
   "source": [
    "# 11. Group Chat Orchestration\n",
    "\n",
    "![Group Chat Pattern](images/group-chat.png)\n",
    "\n",
    "Multiple agents collaborate in a shared conversation, coordinated by an orchestrator.\n",
    "\n",
    "**When to Use:**\n",
    "- Iterative refinement with multiple review rounds\n",
    "- Collaborative problem-solving with shared context\n",
    "- Multi-perspective analysis (e.g., writer-reviewer workflows)\n",
    "\n",
    "**When NOT to Use:**\n",
    "- Agents should work independently (use Concurrent)\n",
    "- Complex dynamic planning needed (use Magentic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38398cec",
   "metadata": {},
   "source": [
    "## Key Differences\n",
    "\n",
    "| Pattern | Coordination | Use Case |\n",
    "|---------|--------------|----------|\n",
    "| **Concurrent** | No coordination | Independent parallel tasks |\n",
    "| **Group Chat** | Orchestrator selects speakers | Iterative refinement, shared context |\n",
    "| **Magentic** | Manager with dynamic planning | Complex open-ended tasks |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105e4d2",
   "metadata": {},
   "source": [
    "## Define Specialists\n",
    "\n",
    "Create agents with distinct review roles. All agents will see the shared conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74b41c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Three specialist reviewers defined:\n",
      "   1. SecurityReviewer - identifies security issues\n",
      "   2. AccuracyReviewer - checks facts and promises\n",
      "   3. ToneReviewer - applies all feedback and produces FINAL email\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import GroupChatBuilder, GroupChatState, ConcurrentBuilder, MagenticBuilder\n",
    "\n",
    "# Three specialized reviewers - order matters! Last one produces final output.\n",
    "\n",
    "# 1st: Security reviewer - identifies security/compliance issues\n",
    "security_reviewer = ChatAgent(\n",
    "    name=\"SecurityReviewer\",\n",
    "    description=\"Security and compliance specialist - reviews first\",\n",
    "    instructions=\"\"\"You are the FIRST reviewer. Analyze the support response for:\n",
    "- Data exposure risks (customer IDs, case numbers that shouldn't be in emails)\n",
    "- PII handling concerns (names, order details)\n",
    "- Policy compliance issues\n",
    "\n",
    "Be concise. List only the security issues you find. Do NOT rewrite the email - just identify problems for later reviewers to address.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# 2nd: Accuracy reviewer - checks facts and promises\n",
    "accuracy_reviewer = ChatAgent(\n",
    "    name=\"AccuracyReviewer\", \n",
    "    description=\"Factual accuracy specialist - reviews second\",\n",
    "    instructions=\"\"\"You are the SECOND reviewer. Analyze the support response for:\n",
    "- Unrealistic promises or timelines\n",
    "- Unverifiable claims\n",
    "- Compensation appropriateness\n",
    "\n",
    "Consider the security feedback from the previous reviewer. Be concise. List only the accuracy issues. Do NOT rewrite the email - just identify problems for the final reviewer to address.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# 3rd: Tone reviewer - applies all feedback and produces final email\n",
    "tone_reviewer = ChatAgent(\n",
    "    name=\"ToneReviewer\",\n",
    "    description=\"Tone specialist and final editor - produces revised email\",\n",
    "    instructions=\"\"\"You are the FINAL reviewer. Your job is to:\n",
    "1. Consider ALL feedback from SecurityReviewer and AccuracyReviewer\n",
    "2. Review the tone and empathy of the original email\n",
    "3. **PRODUCE A FINAL REVISED EMAIL** that:\n",
    "   - Addresses security concerns (remove/mask sensitive identifiers if needed)\n",
    "   - Fixes accuracy issues (realistic timelines, appropriate promises)\n",
    "   - Maintains professional, empathetic tone\n",
    "   - Is ready to send to the customer\n",
    "\n",
    "End your response with the complete revised email in a clear format.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "print(\"âœ… Three specialist reviewers defined:\")\n",
    "print(\"   1. SecurityReviewer - identifies security issues\")\n",
    "print(\"   2. AccuracyReviewer - checks facts and promises\")  \n",
    "print(\"   3. ToneReviewer - applies all feedback and produces FINAL email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27452e67",
   "metadata": {},
   "source": [
    "## Build Group Chat with Round-Robin\n",
    "\n",
    "Simple selection: each reviewer speaks in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4ab3019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Group chat built with round-robin selection\n",
      "   Order: SecurityReviewer â†’ AccuracyReviewer â†’ ToneReviewer (final)\n"
     ]
    }
   ],
   "source": [
    "# Sample draft response to review\n",
    "draft_to_review = \"\"\"\n",
    "Subject: Re: Order #12345 - Delivery Issue\n",
    "\n",
    "Dear Sarah,\n",
    "\n",
    "I'm so sorry to hear about the missing package! This must be incredibly frustrating.\n",
    "\n",
    "I've located your order and can confirm it was marked as delivered on Monday. Here's what I'll do:\n",
    "\n",
    "1. I've opened an investigation with our shipping partner (Case #INV-789)\n",
    "2. As a Premium customer, I'm expediting a replacement shipment TODAY\n",
    "3. The replacement will arrive by Thursday, well before your Friday presentation\n",
    "\n",
    "Your account has also been credited $50 for the inconvenience.\n",
    "\n",
    "If you need anything else, reply directly to this email - I'm here to help!\n",
    "\n",
    "Best regards,\n",
    "Support Team\n",
    "\"\"\"\n",
    "\n",
    "# Round-robin selector: each reviewer speaks in order\n",
    "def round_robin_selector(state: GroupChatState) -> str:\n",
    "    \"\"\"Pick the next speaker based on round index.\"\"\"\n",
    "    participants = list(state.participants.keys())\n",
    "    return participants[state.current_round % len(participants)]\n",
    "\n",
    "# Build group chat with round-robin selection\n",
    "# ORDER MATTERS: Security â†’ Accuracy â†’ Tone (final editor)\n",
    "review_group_chat = (\n",
    "    GroupChatBuilder()\n",
    "    .with_orchestrator(selection_func=round_robin_selector, orchestrator_name=\"RoundRobinOrchestrator\")\n",
    "    .participants([security_reviewer, accuracy_reviewer, tone_reviewer])  # Order: Security â†’ Accuracy â†’ Tone\n",
    "    .with_termination_condition(lambda msgs: len([m for m in msgs if m.role.value == \"assistant\"]) >= 3)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Group chat built with round-robin selection\")\n",
    "print(\"   Order: SecurityReviewer â†’ AccuracyReviewer â†’ ToneReviewer (final)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7588de",
   "metadata": {},
   "source": [
    "## Test Round-Robin Group Chat\n",
    "\n",
    "Each reviewer analyzes the draft in turn, building on previous insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4794a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ DRAFT TO REVIEW:\n",
      "\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "I'm so sorry to hear about the missing package! This must be incredibly frustrating.\n",
      "\n",
      "I've located your order and can confirm it was marked as delivered on Monday. Here's what I'll do:\n",
      "\n",
      "1. I've opened an investigation with our shipping partner (Case #INV-789)\n",
      "2. As a Premium customer, I'm expediting a replacement shipment TODAY\n",
      "3. The replacement will arrive by Thursday, well before your Friday presentation\n",
      "\n",
      "Your account has also been credited $50 for the inconvenience.\n",
      "\n",
      "If you need anything else, reply directly to this email - I'm here to help!\n",
      "\n",
      "Best regards,\n",
      "Support Team\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ ROUND-ROBIN GROUP CHAT (each reviewer speaks in turn):\n",
      "\n",
      "\n",
      "ðŸ¤– [SecurityReviewer] (Turn #1): 1. **Data Exposure Risks:** \n",
      "   - The inclusion of the order number (#12345) and case number (INV-789) in the email could potentially expose sensitive information if this email is intercepted or viewed by unauthorized individuals.\n",
      "\n",
      "2. **PII Handling Concerns:**\n",
      "   - The customerâ€™s name (Sarah) is directly mentioned, which is personally identifiable information (PII) that should be handled with care in email communications.\n",
      "   - Order details (specifics regarding the package and financial compensation) may constitute sensitive information, especially if they could reveal additional insights about the customerâ€™s purchasing behavior or financial status.\n",
      "\n",
      "3. **Policy Compliance Issues:**\n",
      "   - Depending on the companyâ€™s data protection policies, sharing identifiable details and case numbers in email communications may violate internal data handling and privacy protocols.\n",
      "\n",
      "\n",
      "ðŸ¤– [AccuracyReviewer] (Turn #2): 1. **Unrealistic Promises or Timelines:**\n",
      "   - Promising an expedited replacement shipment \"TODAY\" may not align with typical processing and shipping times, particularly if the claim is made without confirming capability with the shipping partner.\n",
      "\n",
      "2. **Unverifiable Claims:**\n",
      "   - Claiming that the replacement will \"arrive by Thursday\" may be unverifiable without assurance from the shipping provider, as unexpected delays can occur.\n",
      "\n",
      "3. **Compensation Appropriateness:**\n",
      "   - The offer of a $50 credit might not reflect the severity of the issue or the inconvenience caused, possibly creating discrepancies in customer satisfaction expectations.\n",
      "\n",
      "\n",
      "ðŸ¤– [ToneReviewer] (Turn #3): Subject: Re: Order - Delivery Issue\n",
      "\n",
      "Dear Valued Customer,\n",
      "\n",
      "Thank you for bringing the issue regarding your package to our attention. I understand how frustrating this situation must be for you, and I want to ensure we resolve it as quickly as possible.\n",
      "\n",
      "I have located your order, which was marked as delivered recently. To address this issue, I have taken the following steps:\n",
      "\n",
      "1. I have initiated an investigation with our shipping partner regarding this delivery.\n",
      "2. As a gesture of goodwill, I will be expediting a replacement shipment for you. While Iâ€™ll do my best to have this processed as quickly as possible, I will keep you informed of the estimated delivery timeline once I receive confirmation from our shipping partner.\n",
      "3. Additionally, I have applied a credit to your account for the inconvenience caused.\n",
      "\n",
      "I truly appreciate your patience as we work to get this sorted out. If you have any further questions or need assistance, please do not hesitate to reply to this email. I am here to help. \n",
      "\n",
      "Thank you for your understanding.\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]  \n",
      "Customer Support Team  \n",
      "\n",
      "============================================================\n",
      "ðŸ“Š EXECUTION ORDER: SecurityReviewer â†’ AccuracyReviewer â†’ ToneReviewer\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the group chat with round-robin selection\n",
    "from agent_framework._workflows._events import AgentRunUpdateEvent\n",
    "\n",
    "async def test_round_robin_group_chat():\n",
    "    print(\"ðŸ“ DRAFT TO REVIEW:\")\n",
    "    print(draft_to_review)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\nðŸ”„ ROUND-ROBIN GROUP CHAT (each reviewer speaks in turn):\\n\")\n",
    "    \n",
    "    last_executor_id: str | None = None\n",
    "    agent_order = []\n",
    "    \n",
    "    async for event in review_group_chat.run_stream(f\"Review this support response:\\n{draft_to_review}\"):\n",
    "        if isinstance(event, AgentRunUpdateEvent):\n",
    "            eid = event.executor_id\n",
    "            if eid != last_executor_id:\n",
    "                if last_executor_id is not None:\n",
    "                    print(\"\\n\")\n",
    "                agent_order.append(eid)\n",
    "                print(f\"\\nðŸ¤– [{eid}] (Turn #{len(agent_order)}):\", end=\" \", flush=True)\n",
    "                last_executor_id = eid\n",
    "            print(event.data, end=\"\", flush=True)\n",
    "        \n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(\"\\n\\n\" + \"=\" * 60)\n",
    "            print(f\"ðŸ“Š EXECUTION ORDER: {' â†’ '.join(agent_order)}\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "await test_round_robin_group_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5350b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ DRAFT TO REVIEW:\n",
      "\n",
      "Subject: Re: Order #12345 - Delivery Issue\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "I'm so sorry to hear about the missing package! This must be incredibly frustrating.\n",
      "\n",
      "I've located your order and can confirm it was marked as delivered on Monday. Here's what I'll do:\n",
      "\n",
      "1. I've opened an investigation with our shipping partner (Case #INV-789)\n",
      "2. As a Premium customer, I'm expediting a replacement shipment TODAY\n",
      "3. The replacement will arrive by Thursday, well before your Friday presentation\n",
      "\n",
      "Your account has also been credited $50 for the inconvenience.\n",
      "\n",
      "If you need anything else, reply directly to this email - I'm here to help!\n",
      "\n",
      "Best regards,\n",
      "Support Team\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ§  AGENT-ORCHESTRATED GROUP CHAT (intelligent speaker selection):\n",
      "\n",
      "\n",
      "ðŸ¤– [SecurityReviewer] (Call #1): 1. Data exposure risks: \n",
      "   - Customer IDs and case numbers included in emails could lead to unauthorized access to sensitive information.\n",
      "\n",
      "2. PII handling concerns: \n",
      "   - Names of customers and order details present in the email increase the risk of exposure of personally identifiable information (PII).\n",
      "\n",
      "3. Policy compliance issues: \n",
      "   - Sharing sensitive data in an unsecured manner (such as through email) may violate data protection policies and regulations.\n",
      "\n",
      "\n",
      "ðŸ¤– [AccuracyReviewer] (Call #1): 1. Unrealistic timelines: \n",
      "   - Promising a fast resolution without specifying a realistic timeframe may create customer dissatisfaction if not met.\n",
      "\n",
      "2. Unverifiable claims: \n",
      "   - Statements about the team's capability to resolve complex issues quickly lack supporting evidence or specific examples.\n",
      "\n",
      "3. Compensation appropriateness: \n",
      "   - The compensation offered may not be proportional to the level of inconvenience caused to the customer, leading to perceptions of unfairness.\n",
      "\n",
      "\n",
      "ðŸ¤– [ToneReviewer] (Call #1): Subject: Update on Your Support Case\n",
      "\n",
      "Dear [Customer's First Name],\n",
      "\n",
      "Thank you for your patience while we work on your support case. We understand that this situation is important to you, and we want to ensure that we address your concerns thoroughly.\n",
      "\n",
      "Currently, our team is investigating the issues you've reported. While we strive to resolve all customer concerns as quickly as possible, itâ€™s essential that we take the necessary time to ensure a comprehensive solution. While I cannot provide an exact timeline, we anticipate having more substantial updates within the next [insert realistic timeframe, e.g., \"7-10 business days\"]. We appreciate your understanding as we work to get this resolved.\n",
      "\n",
      "Additionally, we recognize the inconvenience this may have caused, and while we are committed to assisting you, we want to ensure that any compensation offered is fair and appropriate for the situation. I will follow up with you regarding this matter once we have more information.\n",
      "\n",
      "Please rest assured that your information and privacy are our top priority. If you have any questions in the meantime, feel free to reach out directly.\n",
      "\n",
      "Thank you for your understanding and support.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Your Company]  \n",
      "[Your Contact Information]  \n",
      "\n",
      "(Note: Please ensure that customer identifiers, such as Customer IDs or case numbers, are not included in the email for privacy reasons.)\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š EXECUTION SUMMARY\n",
      "============================================================\n",
      "   Total calls: 3\n",
      "\n",
      "   Calls per agent:\n",
      "      AccuracyReviewer: 1 call(s)\n",
      "      SecurityReviewer: 1 call(s)\n",
      "      ToneReviewer: 1 call(s)\n",
      "\n",
      "   ðŸ’¡ The orchestrator dynamically selected speakers\n",
      "      based on what was needed at each step\n",
      "\n",
      "============================================================\n",
      "ðŸ“§ FINAL REVISED EMAIL (from ToneReviewer)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Agent-based orchestrator for intelligent speaker selection\n",
    "from typing import cast\n",
    "from agent_framework._workflows._events import AgentRunUpdateEvent, WorkflowOutputEvent\n",
    "from agent_framework._types import ChatMessage\n",
    "\n",
    "orchestrator_agent = ChatAgent(\n",
    "    name=\"ReviewOrchestrator\",\n",
    "    description=\"Coordinates multi-agent review process\",\n",
    "    instructions=f\"\"\"You coordinate a team reviewing this support response:\n",
    "\n",
    "{draft_to_review}\n",
    "\n",
    "YOUR TEAM:\n",
    "- SecurityReviewer: Identifies security/PII issues (reviews first)\n",
    "- AccuracyReviewer: Checks facts and promises (reviews second)\n",
    "- ToneReviewer: Final editor who produces the revised email (reviews last)\n",
    "\n",
    "YOUR PROCESS:\n",
    "1. Start with SecurityReviewer to check data safety and PII\n",
    "2. Then AccuracyReviewer to verify claims and timelines\n",
    "3. **Finally, ToneReviewer to produce the FINAL REVISED EMAIL** incorporating all feedback\n",
    "4. If needed, you may ask follow-up questions to any reviewer\n",
    "5. End when ToneReviewer delivers the complete revised email\n",
    "\n",
    "Select speakers intelligently. CRITICAL: ToneReviewer must go last and produce the final email.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# Build group chat with agent-based orchestration\n",
    "# ORDER: Security â†’ Accuracy â†’ Tone (final editor)\n",
    "intelligent_review_chat = (\n",
    "    GroupChatBuilder()\n",
    "    .with_orchestrator(agent=orchestrator_agent)\n",
    "    .participants([security_reviewer, accuracy_reviewer, tone_reviewer])\n",
    "    .with_termination_condition(lambda msgs: len([m for m in msgs if m.role.value == \"assistant\"]) >= 5)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Run with detailed logging\n",
    "async def test_agent_orchestrated_group_chat():\n",
    "    print(\"ðŸ“ DRAFT TO REVIEW:\")\n",
    "    print(draft_to_review)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\nðŸ§  AGENT-ORCHESTRATED GROUP CHAT (intelligent speaker selection):\\n\")\n",
    "    \n",
    "    last_executor_id: str | None = None\n",
    "    agent_calls: dict[str, int] = {}\n",
    "    \n",
    "    async for event in intelligent_review_chat.run_stream(\"Review this support response. Security and Accuracy reviewers identify issues, then ToneReviewer produces the final revised email.\"):\n",
    "        if isinstance(event, AgentRunUpdateEvent):\n",
    "            eid = event.executor_id\n",
    "            if eid != last_executor_id:\n",
    "                if last_executor_id is not None:\n",
    "                    print(\"\\n\")\n",
    "                agent_calls[eid] = agent_calls.get(eid, 0) + 1\n",
    "                print(f\"\\nðŸ¤– [{eid}] (Call #{agent_calls[eid]}):\", end=\" \", flush=True)\n",
    "                last_executor_id = eid\n",
    "            print(event.data, end=\"\", flush=True)\n",
    "        \n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            output_messages = cast(list[ChatMessage], event.data)\n",
    "            \n",
    "            print(\"\\n\\n\" + \"=\" * 60)\n",
    "            print(\"ðŸ“Š EXECUTION SUMMARY\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"   Total calls: {sum(agent_calls.values())}\")\n",
    "            print(\"\\n   Calls per agent:\")\n",
    "            for agent, count in sorted(agent_calls.items()):\n",
    "                print(f\"      {agent}: {count} call(s)\")\n",
    "            \n",
    "            print(\"\\n   ðŸ’¡ The orchestrator dynamically selected speakers\")\n",
    "            print(\"      based on what was needed at each step\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"ðŸ“§ FINAL REVISED EMAIL (from ToneReviewer)\")\n",
    "            print(\"=\" * 60)\n",
    "            for msg in reversed(output_messages):\n",
    "                if msg.role.value == \"assistant\" and \"ToneReviewer\" in str(msg):\n",
    "                    print(msg.text)\n",
    "                    break\n",
    "\n",
    "await test_agent_orchestrated_group_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e052",
   "metadata": {},
   "source": [
    "# 12. Magentic Orchestration\n",
    "\n",
    "![Magentic Pattern](images/magentic-workflow.png)\n",
    "\n",
    "Magentic is the most powerful orchestration pattern - a manager dynamically plans and delegates to specialists based on evolving task requirements.\n",
    "\n",
    "**When to Use:**\n",
    "- Complex, open-ended tasks requiring multiple iterations\n",
    "- Tasks where the solution path isn't known in advance\n",
    "- Research + analysis workflows with code execution\n",
    "\n",
    "**When NOT to Use:**\n",
    "- Simple linear pipelines (use Sequential)\n",
    "- Fixed review rounds (use Group Chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0d883",
   "metadata": {},
   "source": [
    "## Use Case: Market Research Report\n",
    "\n",
    "A complex task requiring:\n",
    "1. **Research Agent** - Web search for current data\n",
    "2. **Analyst Agent** - Code execution for data processing\n",
    "3. **Manager** - Dynamic planning and synthesis\n",
    "\n",
    "The manager autonomously decides which agent to call and when based on progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸš€ SUPPORT EMAIL COPILOT - CAPSTONE DEMO\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ“§ PROCESSING: LEGITIMATE SUPPORT REQUEST\n",
      "======================================================================\n",
      "From: sarah.chen@acmecorp.com\n",
      "Subject: Order #12345 - Delivery Issue\n",
      "Customer ID: CUST-7891\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ“Š Step 1: CLASSIFICATION\n",
      "   Category: not_spam\n",
      "   Confidence: 95%\n",
      "   Reason: The email is from a corporate domain and discusses a legitimate delivery issue, likely from a real customer.\n",
      "\n",
      "ðŸ” Step 3: CUSTOMER LOOKUP\n",
      "   SLA: Customer CUST-7891: Premium tier, 4 hours response time, Free expedited replacement\n",
      "   Ticket: Ticket TKT-2024-001: Status=Open, Priority=High, Assigned to=Support Team, Last update=2024-01-15\n",
      "\n",
      "âœï¸ Step 4: DRAFTING RESPONSE\n",
      "   Subject: Re: Order #12345 - Delivery Issue\n",
      "   Tone: apologetic\n",
      "   Body preview: Dear Ms. Chen,\n",
      "\n",
      "Thank you for reaching out to us regarding the delivery issue with your recent order.\n",
      "\n",
      "I sincerely apologize for the inconvenience this has caused, especially with your client presenta...\n",
      "\n",
      "ðŸ” Step 5: MULTI-AGENT REVIEW (parallel)\n",
      "   Reviewer 1: Top concerns from the draft response:\n",
      "\n",
      "1. **Sensitive Data Exposure**: Ensure that no personal or sensitive information is included in the email. The ...\n",
      "   Reviewer 2: **Tone Assessment:**\n",
      "- Professional: Yes\n",
      "- Empathetic: Yes\n",
      "- Defensive: No\n",
      "\n",
      "**Suggestions for Improvement:**\n",
      "1. **Reassurance:** Include a brief sente...\n",
      "   Reviewer 3: Concerns:\n",
      "\n",
      "1. **Lack of Specific Timeline**: The draft mentions a follow-up to provide updates but doesn't set a clear timeline, which may leave the c...\n",
      "\n",
      "âœ… Step 6: FINAL OUTPUT\n",
      "   Status: Ready for approval\n",
      "   Draft approved for sending to: sarah.chen@acmecorp.com\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ“§ PROCESSING: SPAM\n",
      "======================================================================\n",
      "From: winner@prize-notifications.biz\n",
      "Subject: ðŸŽ‰ CONGRATULATIONS! You've WON $1,000,000!!!\n",
      "Customer ID: None\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ“Š Step 1: CLASSIFICATION\n",
      "   Category: spam\n",
      "   Confidence: 95%\n",
      "   Reason: The email is from a suspicious address, promises a large sum of money, requests personal information and a fee, which are common signs of lottery scams.\n",
      "\n",
      "ðŸš« Step 2: ROUTED TO SPAM HANDLER\n",
      "   Result: Email blocked and logged\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ“§ PROCESSING: AMBIGUOUS / UNCERTAIN\n",
      "======================================================================\n",
      "From: j.smith@unknown-domain.net\n",
      "Subject: Partnership Opportunity\n",
      "Customer ID: None\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ“Š Step 1: CLASSIFICATION\n",
      "   Category: uncertain\n",
      "   Confidence: 65%\n",
      "   Reason: The email is from an unknown domain and presents a business opportunity, which is often typical of spam, but it does not contain obvious red flags and appears to be a legitimate outreach.\n",
      "\n",
      "âš ï¸ Step 2: ROUTED TO HUMAN REVIEW\n",
      "   Result: Flagged for manual review\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ CAPSTONE DEMO COMPLETE\n",
      "======================================================================\n",
      "\n",
      "You've seen the complete Support Email Copilot system:\n",
      "â€¢ Classification with routing (Spam/NotSpam/Uncertain)\n",
      "â€¢ Customer lookup via function tools\n",
      "â€¢ Response drafting with structured output\n",
      "â€¢ Multi-agent concurrent review\n",
      "â€¢ End-to-end processing pipeline\n"
     ]
    }
   ],
   "source": [
    "# Magentic Orchestration: Research + Analysis workflow\n",
    "import json\n",
    "from typing import cast\n",
    "from agent_framework import (\n",
    "    AgentRunUpdateEvent,\n",
    "    MagenticOrchestratorEvent,\n",
    "    MagenticProgressLedger,\n",
    ")\n",
    "\n",
    "# Research Agent - uses web search capability\n",
    "# Note: In production, use OpenAI's gpt-4o-search-preview or add web search tools\n",
    "researcher_agent = ChatAgent(\n",
    "    name=\"ResearcherAgent\",\n",
    "    description=\"Specialist in research and information gathering about markets, trends, and data\",\n",
    "    instructions=\"\"\"You are a Research Specialist. Your job is to:\n",
    "- Gather factual information about topics\n",
    "- Find current statistics and trends\n",
    "- Provide sources for your findings\n",
    "\n",
    "When asked about market data, provide realistic example data with citations.\n",
    "Be concise and factual. Format data clearly for analysis.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# Analyst Agent - processes and analyzes data\n",
    "# Note: In production, add HostedCodeInterpreterTool for real code execution\n",
    "analyst_agent = ChatAgent(\n",
    "    name=\"AnalystAgent\",\n",
    "    description=\"Data analyst who processes information and creates insights with calculations\",\n",
    "    instructions=\"\"\"You are a Data Analyst. Your job is to:\n",
    "- Process and analyze data provided by the researcher\n",
    "- Perform calculations (growth rates, comparisons, projections)\n",
    "- Create clear tables and visualizations descriptions\n",
    "- Identify trends and insights\n",
    "\n",
    "Show your calculations step by step. Format results in clear tables.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# Manager Agent - orchestrates the research workflow\n",
    "manager_agent = ChatAgent(\n",
    "    name=\"ResearchManager\",\n",
    "    description=\"Orchestrator that coordinates research and analysis workflows\",\n",
    "    instructions=\"\"\"You manage a research team to complete comprehensive analysis tasks.\n",
    "\n",
    "YOUR TEAM:\n",
    "- ResearcherAgent: Gathers information, statistics, and market data\n",
    "- AnalystAgent: Processes data, performs calculations, creates insights\n",
    "\n",
    "YOUR PROCESS:\n",
    "1. Break down the research request into subtasks\n",
    "2. Delegate to ResearcherAgent to gather relevant data\n",
    "3. Delegate to AnalystAgent to process and analyze the data\n",
    "4. Continue iterating until you have comprehensive insights\n",
    "5. Synthesize all findings into a final report\n",
    "\n",
    "You dynamically decide who to call based on what's needed. You may call agents multiple times.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "print(\"âœ… Magentic agents defined: ResearcherAgent, AnalystAgent, ResearchManager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ddaa3",
   "metadata": {},
   "source": [
    "## Build & Run Magentic Workflow\n",
    "\n",
    "The manager dynamically plans and delegates. Watch how it calls different agents based on the evolving task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919845da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Magentic workflow\n",
    "magentic_research_workflow = (\n",
    "    MagenticBuilder()\n",
    "    .participants([researcher_agent, analyst_agent])\n",
    "    .with_manager(\n",
    "        agent=manager_agent,\n",
    "        max_round_count=10,  # Maximum delegation rounds\n",
    "        max_stall_count=2,   # Replan after 2 stalls\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Research task - complex enough to require multiple agent interactions\n",
    "research_task = \"\"\"\n",
    "Analyze the global electric vehicle (EV) market:\n",
    "1. Find the top 5 EV manufacturers by market share\n",
    "2. Calculate year-over-year growth rates\n",
    "3. Compare EV adoption rates in US, Europe, and China\n",
    "4. Provide a summary table and key insights\n",
    "\"\"\"\n",
    "\n",
    "async def run_magentic_research():\n",
    "    print(\"ðŸ”¬ MAGENTIC RESEARCH WORKFLOW\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ðŸ“‹ TASK:\\n{research_task}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    last_message_id: str | None = None\n",
    "    agent_calls: dict[str, int] = {}\n",
    "    \n",
    "    async for event in magentic_research_workflow.run_stream(research_task):\n",
    "        # Track streaming from agents\n",
    "        if isinstance(event, AgentRunUpdateEvent):\n",
    "            message_id = event.data.message_id\n",
    "            executor_id = event.executor_id\n",
    "            \n",
    "            if message_id != last_message_id:\n",
    "                if last_message_id is not None:\n",
    "                    print(\"\\n\")\n",
    "                agent_calls[executor_id] = agent_calls.get(executor_id, 0) + 1\n",
    "                print(f\"\\nðŸ¤– [{executor_id}] (Call #{agent_calls[executor_id]}):\", end=\" \", flush=True)\n",
    "                last_message_id = message_id\n",
    "            \n",
    "            print(event.data, end=\"\", flush=True)\n",
    "        \n",
    "        # Track orchestration events\n",
    "        elif isinstance(event, MagenticOrchestratorEvent):\n",
    "            print(f\"\\n\\n{'='*55}\")\n",
    "            print(f\"ðŸ“‹ ORCHESTRATOR: {event.event_type.name}\")\n",
    "            print(f\"{'='*55}\")\n",
    "            \n",
    "            if isinstance(event.data, MagenticProgressLedger):\n",
    "                ledger = event.data.to_dict()\n",
    "                if \"next_speaker\" in ledger:\n",
    "                    next_info = ledger.get('next_speaker', {})\n",
    "                    if isinstance(next_info, dict):\n",
    "                        print(f\"   âž¡ï¸ Next: {next_info.get('answer', 'N/A')}\")\n",
    "                        reason = next_info.get('reason', '')\n",
    "                        if reason:\n",
    "                            print(f\"   ðŸ’­ Why: {reason[:100]}...\")\n",
    "                    else:\n",
    "                        print(f\"   âž¡ï¸ Next: {next_info}\")\n",
    "        \n",
    "        # Final output\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            output_messages = cast(list[ChatMessage], event.data)\n",
    "            \n",
    "            print(\"\\n\\n\" + \"=\" * 60)\n",
    "            print(\"ðŸ“Š EXECUTION SUMMARY\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"   Total agent calls: {sum(agent_calls.values())}\")\n",
    "            print(\"\\n   Calls per agent:\")\n",
    "            for agent, count in sorted(agent_calls.items()):\n",
    "                print(f\"      {agent}: {count} call(s)\")\n",
    "            \n",
    "            print(\"\\n   âœ¨ Manager dynamically orchestrated:\")\n",
    "            print(f\"      - Broke down complex task into subtasks\")\n",
    "            print(f\"      - Called ResearcherAgent for data gathering\")\n",
    "            print(f\"      - Called AnalystAgent for processing\")\n",
    "            print(f\"      - Synthesized into final report\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"ðŸ“‘ FINAL RESEARCH REPORT\")\n",
    "            print(\"=\" * 60)\n",
    "            for msg in reversed(output_messages):\n",
    "                if msg.role.value == \"assistant\":\n",
    "                    print(msg.text)\n",
    "                    break\n",
    "\n",
    "await run_magentic_research()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
